{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83916d5c-847d-4008-b2a0-cf1a24e8ab3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "import seaborn as sns\n",
    "import ptitprince as pt # rainplot\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec45ccb-f5c6-45bf-bdf9-627bd1e9c037",
   "metadata": {},
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ceb57213-a7a8-408d-906a-9fd6def7846e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hits_fbs(df):\n",
    "    \n",
    "    isHit_all_cues = {}\n",
    "    fbs_all_cues = {}\n",
    "    trialNo_all_cues = {}\n",
    "        \n",
    "    for cue in ['HR', 'LR', 'HP', 'LP']:\n",
    "\n",
    "        # Extract cue data\n",
    "        cue_data_tmp = df[df['Code']==('Cue_' + cue)] \n",
    "\n",
    "        # Create a cue trial column\n",
    "        cue_data_tmp.insert(0, \"CueTrial\", list(range(1,len(cue_data_tmp)+1)))\n",
    "\n",
    "        # Store all in dictionnaries\n",
    "        isHit_all_cues[cue]=cue_data_tmp['isHit'].tolist()\n",
    "        fbs_all_cues[cue]=cue_data_tmp['FBs'].tolist()\n",
    "        trialNo_all_cues[cue]=cue_data_tmp['Trial'].tolist()\n",
    "        \n",
    "    return isHit_all_cues, fbs_all_cues, trialNo_all_cues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc33407-ae4b-4877-b8bb-8efeacf9965c",
   "metadata": {},
   "source": [
    "# Value functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6371fa5f-151a-4f5b-a2f3-8ff88f98d6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescorla_wagner_2LR_FB_noV0(fbs_all_cues, trialNo_all_cues, param_values, param_names, isHit_all_cues):\n",
    "    \n",
    "    # Fixed parameter\n",
    "    v0 = 0\n",
    "    \n",
    "    # Free parameters\n",
    "    alpha_rew = param_values[param_names.index('alpha_rew')]\n",
    "    alpha_pun = param_values[param_names.index('alpha_pun')]\n",
    "    \n",
    "    # Initialise empty dicitonnary\n",
    "    vt_all_cues = dict.fromkeys(fbs_all_cues.keys())\n",
    "    pe_all_cues = dict.fromkeys(fbs_all_cues.keys())\n",
    "    \n",
    "    # Iterate over cues\n",
    "    for cue, fbs, hits in zip(fbs_all_cues.keys(), fbs_all_cues.values(), isHit_all_cues.values()):\n",
    "        \n",
    "        # Initialise vector of values\n",
    "        vt = np.empty(len(fbs))\n",
    "        vt.fill(np.nan)\n",
    "        \n",
    "        # Initialise vector of PEs\n",
    "        pe = np.empty(len(fbs))\n",
    "        pe.fill(np.nan)\n",
    "        \n",
    "        # Fill in prior\n",
    "        # If want specific prior per cue, check value of cue\n",
    "        vt[0] = v0\n",
    "        \n",
    "        # Iterate to fill in vector\n",
    "        for t in range(1,len(vt)):\n",
    "            \n",
    "            # if hit, recieves fb\n",
    "            if hits[t-1] == 1:\n",
    "            \n",
    "                # Compute prediction error\n",
    "                pe[t-1] = fbs[t-1] - vt[t-1]\n",
    "\n",
    "                # Compute new vt and fill in \n",
    "                if fbs[t-1] > 0:\n",
    "                    vt[t] = vt[t-1] + alpha_rew * pe[t-1]\n",
    "                elif fbs[t-1] < 0:\n",
    "                    vt[t] = vt[t-1] + alpha_pun * pe[t-1]\n",
    "                else:\n",
    "                    print('error, fb either 0 or nan?')\n",
    "                    \n",
    "            # if no hit, no fb\n",
    "            elif hits[t-1] == 0:\n",
    "                # vt does not change \n",
    "                vt[t] = vt[t-1] \n",
    "                \n",
    "        vt_all_cues[cue] = vt\n",
    "        pe_all_cues[cue] = pe\n",
    "    \n",
    "    return vt_all_cues, pe_all_cues, []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42013a82-1712-425b-aa48-f14ca98bd5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescorla_wagner_2LR_FB(fbs_all_cues, trialNo_all_cues, param_values, param_names, isHit_all_cues):\n",
    "    \n",
    "    # Free parameters\n",
    "    v0 = param_values[param_names.index('v0')]\n",
    "    alpha_rew = param_values[param_names.index('alpha_rew')]\n",
    "    alpha_pun = param_values[param_names.index('alpha_pun')]\n",
    "    \n",
    "    # Initialise empty dicitonnary\n",
    "    vt_all_cues = dict.fromkeys(fbs_all_cues.keys())\n",
    "    pe_all_cues = dict.fromkeys(fbs_all_cues.keys())\n",
    "    \n",
    "    # Iterate over cues\n",
    "    for cue, fbs, hits in zip(fbs_all_cues.keys(), fbs_all_cues.values(), isHit_all_cues.values()):\n",
    "                \n",
    "        # Initialise vector of values\n",
    "        vt = np.empty(len(fbs))\n",
    "        vt.fill(np.nan)\n",
    "        \n",
    "        # Initialise vector of PEs\n",
    "        pe = np.empty(len(fbs))\n",
    "        pe.fill(np.nan)\n",
    "        \n",
    "        # Fill in prior\n",
    "        # If want specific prior per cue, check value of cue\n",
    "        vt[0] = v0\n",
    "        \n",
    "        # Iterate to fill in vector\n",
    "        for t in range(1,len(vt)):\n",
    "            \n",
    "            # if hit, recieves fb\n",
    "            if hits[t-1] == 1:\n",
    "            \n",
    "                # Compute prediction error\n",
    "                pe[t-1] = fbs[t-1] - vt[t-1]\n",
    "\n",
    "                # Compute new vt and fill in \n",
    "                if fbs[t-1] > 0:\n",
    "                    vt[t] = vt[t-1] + alpha_rew * pe[t-1]\n",
    "                elif fbs[t-1] < 0:\n",
    "                    vt[t] = vt[t-1] + alpha_pun * pe[t-1]\n",
    "                else:\n",
    "                    print('error, fb either 0 or nan?')\n",
    "                    \n",
    "            # if no hit, no fb\n",
    "            elif hits[t-1] == 0:\n",
    "                # vt does not change \n",
    "                vt[t] = vt[t-1] \n",
    "                \n",
    "                \n",
    "        vt_all_cues[cue] = vt\n",
    "        pe_all_cues[cue] = pe\n",
    "    \n",
    "    return vt_all_cues, pe_all_cues, []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3099f97f-b515-4f23-8653-f306c8fac80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescorla_wagner_2LR_PE(fbs_all_cues, trialNo_all_cues, param_values, param_names, isHit_all_cues):\n",
    "    \n",
    "    # Free parameters\n",
    "    v0 = param_values[param_names.index('v0')]\n",
    "    alpha_pos = param_values[param_names.index('alpha_pos')]\n",
    "    alpha_neg = param_values[param_names.index('alpha_neg')]\n",
    "    \n",
    "    # Initialise empty dicitonnary\n",
    "    vt_all_cues = dict.fromkeys(fbs_all_cues.keys())\n",
    "    pe_all_cues = dict.fromkeys(fbs_all_cues.keys())\n",
    "    \n",
    "    # Iterate over cues\n",
    "    for cue, fbs, hits in zip(fbs_all_cues.keys(), fbs_all_cues.values(), isHit_all_cues.values()):\n",
    "        \n",
    "        # Initialise vector of values\n",
    "        vt = np.empty(len(fbs))\n",
    "        vt.fill(np.nan)\n",
    "        \n",
    "        # Initialise vector of PEs\n",
    "        pe = np.empty(len(fbs))\n",
    "        pe.fill(np.nan)\n",
    "        \n",
    "        # Fill in prior\n",
    "        # If want specific prior per cue, check value of cue\n",
    "        vt[0] = v0\n",
    "        \n",
    "        # Iterate to fill in vector\n",
    "        for t in range(1,len(vt)):\n",
    "            \n",
    "            # if hit, recieves fb\n",
    "            if hits[t-1] == 1:\n",
    "            \n",
    "                # Compute prediction error\n",
    "                pe[t-1] = fbs[t-1] - vt[t-1]\n",
    "\n",
    "                # Compute new vt and fill in \n",
    "                if pe >= 0:\n",
    "                    vt[t] = vt[t-1] + alpha_pos * pe[t-1]\n",
    "                elif pe < 0:\n",
    "                    vt[t] = vt[t-1] + alpha_neg * pe[t-1]\n",
    "                else:\n",
    "                    print('error')\n",
    "                    \n",
    "            # if no hit, no fb\n",
    "            elif hits[t-1] == 0:\n",
    "                # vt does not change \n",
    "                vt[t] = vt[t-1] \n",
    "                \n",
    "        vt_all_cues[cue] = vt\n",
    "        pe_all_cues[cue] = pe\n",
    "    \n",
    "    return vt_all_cues, pe_all_cues, []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b06904-d4aa-40bf-bb69-b76fb0c73122",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescorla_wagner_weightRew(fbs_all_cues, trialNo_all_cues, param_values, param_names, isHit_all_cues):\n",
    "    \n",
    "    # Free parameters\n",
    "    v0 = param_values[param_names.index('v0')]\n",
    "    alpha = param_values[param_names.index('alpha')]\n",
    "    w = param_values[param_names.index('w')]\n",
    "    \n",
    "    # Initialise empty dicitonnary\n",
    "    vt_all_cues = dict.fromkeys(fbs_all_cues.keys())\n",
    "    pe_all_cues = dict.fromkeys(fbs_all_cues.keys())\n",
    "    \n",
    "    # Iterate over cues\n",
    "    for cue, fbs, hits in zip(fbs_all_cues.keys(), fbs_all_cues.values(), isHit_all_cues.values()):\n",
    "        \n",
    "        # Initialise vector of values\n",
    "        vt = np.empty(len(fbs))\n",
    "        vt.fill(np.nan)\n",
    "        \n",
    "        # Initialise vector of PEs\n",
    "        pe = np.empty(len(fbs))\n",
    "        pe.fill(np.nan)\n",
    "        \n",
    "        # Fill in prior\n",
    "        # If want specific prior per cue, check value of cue\n",
    "        vt[0] = v0\n",
    "        \n",
    "        # Iterate to fill in vector\n",
    "        for t in range(1,len(vt)):\n",
    "            \n",
    "            # if hit, recieves fb\n",
    "            if hits[t-1] == 1:\n",
    "            \n",
    "               # scale fb\n",
    "                if abs(fbs[t-1]) == 5: \n",
    "                    fbs[t-1] = w * fbs[t-1] \n",
    "\n",
    "                # Compute prediction error\n",
    "                pe[t-1] = fbs[t-1] - vt[t-1]\n",
    "\n",
    "                # Compute new vt and fill in \n",
    "                vt[t] = vt[t-1] + alpha * pe[t-1]\n",
    "                \n",
    "            # if no hit, no fb\n",
    "            elif hits[t-1] == 0:\n",
    "                # vt does not change \n",
    "                vt[t] = vt[t-1] \n",
    "        \n",
    "        vt_all_cues[cue] = vt\n",
    "        pe_all_cues[cue] = pe\n",
    "    \n",
    "    return vt_all_cues, pe_all_cues, []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ff02e9-3a0b-4acf-b1f4-4211012caee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescorla_wagner_noV0(fbs_all_cues, trialNo_all_cues, param_values, param_names, isHit_all_cues):\n",
    "    \n",
    "    # Fixed parameter\n",
    "    v0 = 0\n",
    "        \n",
    "    # Free parameters\n",
    "    alpha = param_values[param_names.index('alpha')]\n",
    "    \n",
    "    # Initialise empty dictionnary\n",
    "    vt_all_cues = dict.fromkeys(fbs_all_cues.keys())\n",
    "    pe_all_cues = dict.fromkeys(fbs_all_cues.keys())\n",
    "    \n",
    "    # Iterate over cues\n",
    "    for cue, fbs, hits in zip(fbs_all_cues.keys(), fbs_all_cues.values(), isHit_all_cues.values()):\n",
    "        \n",
    "        # Initialise vector of values\n",
    "        vt = np.empty(len(fbs))\n",
    "        vt.fill(np.nan)\n",
    "        \n",
    "        # Initialise vector of PEs\n",
    "        pe = np.empty(len(fbs))\n",
    "        pe.fill(np.nan)\n",
    "        \n",
    "        # Fill in prior\n",
    "        # If want specific prior per cue, check value of cue\n",
    "        vt[0] = v0\n",
    "        \n",
    "        # Iterate to fill in vector\n",
    "        for t in range(1,len(vt)):\n",
    "            \n",
    "            # if hit, recieves fb\n",
    "            if hits[t-1] == 1:\n",
    "\n",
    "                # Compute prediction error\n",
    "                pe[t-1] = fbs[t-1] - vt[t-1]\n",
    "\n",
    "                # Compute new vt and fill in \n",
    "                vt[t] = vt[t-1] + alpha * pe[t-1]\n",
    "\n",
    "            # if no hit, no fb\n",
    "            elif hits[t-1] == 0:\n",
    "                # vt does not change \n",
    "                vt[t] = vt[t-1] \n",
    "                \n",
    "        vt_all_cues[cue] = vt\n",
    "        pe_all_cues[cue] = pe\n",
    "    \n",
    "    return vt_all_cues, pe_all_cues, []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71f01eb-157c-49b9-b54c-f8170dd88589",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescorla_wagner_press_bias(fbs_all_cues, trialNo_all_cues, param_values, param_names, isHit_all_cues):\n",
    "    \n",
    "    # Free parameters\n",
    "    v0 = param_values[param_names.index('v0')]\n",
    "    alpha = param_values[param_names.index('alpha')]\n",
    "    pi = param_values[param_names.index('pi')]\n",
    "    \n",
    "    # Initialise empty dicitonnary\n",
    "    vt_all_cues = dict.fromkeys(fbs_all_cues.keys())\n",
    "    pe_all_cues = dict.fromkeys(fbs_all_cues.keys())\n",
    "    \n",
    "    # Iterate over cues\n",
    "    for cue, fbs, hits in zip(fbs_all_cues.keys(), fbs_all_cues.values(), isHit_all_cues.values()):\n",
    "        \n",
    "        # Initialise vector of values\n",
    "        vt = np.empty(len(fbs))\n",
    "        vt.fill(np.nan)\n",
    "        \n",
    "        # Initialise vector of PEs\n",
    "        pe = np.empty(len(fbs))\n",
    "        pe.fill(np.nan)\n",
    "        \n",
    "        # Fill in prior\n",
    "        # If want specific prior per cue, check value of cue\n",
    "        vt[0] = v0\n",
    "        \n",
    "        # Iterate to fill in vector\n",
    "        for t in range(1,len(vt)):\n",
    "            \n",
    "            # if hit, recieves fb\n",
    "            if hits[t-1] == 1:\n",
    "            \n",
    "                # Compute prediction error\n",
    "                pe[t-1] = fbs[t-1] - vt[t-1]\n",
    "\n",
    "                # Compute new vt and fill in \n",
    "                vt[t] = vt[t-1] + alpha * pe[t-1] + pi\n",
    "                \n",
    "            # if no hit, no fb\n",
    "            elif hits[t-1] == 0:\n",
    "                # vt does not change \n",
    "                vt[t] = vt[t-1] \n",
    "        \n",
    "        vt_all_cues[cue] = vt\n",
    "        pe_all_cues[cue] = pe\n",
    "    \n",
    "    return vt_all_cues, pe_all_cues, []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41743953-214e-459b-bb04-c03c6519f436",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescorla_wagner_shrinking_alpha_noV0(fbs_all_cues, trialNo_all_cues, param_values, param_names, isHit_all_cues):\n",
    "    \n",
    "    # Fixed parameter\n",
    "    v0 = 0\n",
    "    \n",
    "    # Free parameters\n",
    "    alpha_t = param_values[param_names.index('alpha_t')]\n",
    "    \n",
    "    # Number of trials\n",
    "    Ntrials = sum(len(lst) for lst in fbs_all_cues.values())\n",
    "    \n",
    "    # Initialise empty dicitonnary\n",
    "    vt_all_cues = dict.fromkeys(fbs_all_cues.keys())\n",
    "    pe_all_cues = dict.fromkeys(fbs_all_cues.keys())\n",
    "        \n",
    "    # Iterate over cues\n",
    "    for cue, fbs, hits in zip(fbs_all_cues.keys(), fbs_all_cues.values(), isHit_all_cues.values()):\n",
    "        \n",
    "        trials = trialNo_all_cues[cue]\n",
    "        \n",
    "        # Initialise vector of values\n",
    "        vt = np.empty(len(fbs))\n",
    "        vt.fill(np.nan)\n",
    "        \n",
    "        # Initialise vector of PEs\n",
    "        pe = np.empty(len(fbs))\n",
    "        pe.fill(np.nan)\n",
    "        \n",
    "        # Fill in prior\n",
    "        # If want specific prior per cue, check value of cue\n",
    "        vt[0] = v0\n",
    "                \n",
    "        # Iterate to fill in vector\n",
    "        for t in range(1,len(trials)):\n",
    "            \n",
    "            # if hit, recieves fb\n",
    "            if hits[t-1] == 1:\n",
    "            \n",
    "                trial = trials[t-1]\n",
    "\n",
    "                # Compute prediction error\n",
    "                pe[t-1] = fbs[t-1] - vt[t-1]\n",
    "\n",
    "                # Compute new vt and fill in \n",
    "                shrink = (Ntrials - trial)/Ntrials\n",
    "                vt[t] = vt[t-1] + (alpha_t * shrink)  * pe[t-1]\n",
    "                \n",
    "            # if no hit, no fb\n",
    "            elif hits[t-1] == 0:\n",
    "                # vt does not change \n",
    "                vt[t] = vt[t-1] \n",
    "        \n",
    "        vt_all_cues[cue] = vt\n",
    "        pe_all_cues[cue] = pe\n",
    "    \n",
    "    return vt_all_cues, pe_all_cues, []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124c395b-9702-49e9-9f5e-3452c63aed49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescorla_wagner_shrinking_alpha(fbs_all_cues, trialNo_all_cues, param_values, param_names, isHit_all_cues):\n",
    "        \n",
    "    # Free parameters\n",
    "    v0 = param_values[param_names.index('v0')]\n",
    "    alpha_t = param_values[param_names.index('alpha_t')]\n",
    "    \n",
    "    # Number of trials\n",
    "    Ntrials = sum(len(lst) for lst in fbs_all_cues.values())\n",
    "    \n",
    "    # Initialise empty dictionnary\n",
    "    vt_all_cues = dict.fromkeys(fbs_all_cues.keys())\n",
    "    pe_all_cues = dict.fromkeys(fbs_all_cues.keys())\n",
    "    shrinking_alpha_all_cues = dict.fromkeys(fbs_all_cues.keys())\n",
    "        \n",
    "    # Iterate over cues\n",
    "    for cue, fbs, hits in zip(fbs_all_cues.keys(), fbs_all_cues.values(), isHit_all_cues.values()):\n",
    "        \n",
    "        trials = trialNo_all_cues[cue]\n",
    "        \n",
    "        # Initialise vector of values\n",
    "        vt = np.empty(len(fbs))\n",
    "        vt.fill(np.nan)\n",
    "        \n",
    "        # Initialise vector of alphas\n",
    "        shrinking_alpha = np.empty(len(fbs))\n",
    "        shrinking_alpha.fill(np.nan)\n",
    "        \n",
    "        # Initialise vector of PEs\n",
    "        pe = np.empty(len(fbs))\n",
    "        pe.fill(np.nan)\n",
    "        \n",
    "        # Fill in prior\n",
    "        # If want specific prior per cue, check value of cue\n",
    "        vt[0] = v0\n",
    "                \n",
    "        # Iterate to fill in vector\n",
    "        for t in range(1,len(trials)):\n",
    "            \n",
    "            # if hit, recieves fb\n",
    "            if hits[t-1] == 1:\n",
    "                        \n",
    "                trial = trials[t-1]\n",
    "\n",
    "                # Compute prediction error\n",
    "                pe[t-1] = fbs[t-1] - vt[t-1]\n",
    "\n",
    "                # Compute new vt and fill in \n",
    "                shrink = (Ntrials - trial)/Ntrials\n",
    "                shrinking_alpha[t-1] = alpha_t * shrink\n",
    "                vt[t] = vt[t-1] + shrinking_alpha[t-1] * pe[t-1]\n",
    "                \n",
    "            # if no hit, no fb\n",
    "            elif hits[t-1] == 0:\n",
    "                # vt does not change \n",
    "                vt[t] = vt[t-1] \n",
    "        \n",
    "        shrinking_alpha_all_cues[cue] = shrinking_alpha\n",
    "        vt_all_cues[cue] = vt\n",
    "        pe_all_cues[cue] = pe\n",
    "    \n",
    "    return vt_all_cues, pe_all_cues, shrinking_alpha_all_cues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5801ce-917f-4b88-9837-023f16f8b7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescorla_wagner_reinitV0(fbs_all_cues, trialNo_all_cues, param_values, param_names, isHit_all_cues):\n",
    "    \n",
    "    # Free parameters\n",
    "    v0r = param_values[param_names.index('v0r')]\n",
    "    alpha = param_values[param_names.index('alpha')]\n",
    "    \n",
    "    # Number of trials\n",
    "    Ntrials = sum(len(lst) for lst in fbs_all_cues.values())\n",
    "    \n",
    "    # Initialise empty dicitonnary\n",
    "    vt_all_cues = dict.fromkeys(fbs_all_cues.keys())\n",
    "    pe_all_cues = dict.fromkeys(fbs_all_cues.keys())\n",
    "    \n",
    "    # Iterate over cues\n",
    "    for cue, fbs, hits in zip(fbs_all_cues.keys(), fbs_all_cues.values(), isHit_all_cues.values()):\n",
    "        \n",
    "        trials = trialNo_all_cues[cue]\n",
    "        \n",
    "        # Initialise vector of values\n",
    "        vt = np.empty(len(fbs))\n",
    "        vt.fill(np.nan)\n",
    "        \n",
    "        # Initialise vector of PEs\n",
    "        pe = np.empty(len(fbs))\n",
    "        pe.fill(np.nan)\n",
    "        \n",
    "        # Fill in prior\n",
    "        # If want specific prior per cue, check value of cue\n",
    "        vt[0] = v0r\n",
    "        \n",
    "        # Iterate to fill in vector\n",
    "        for t in range(1,len(trials)):\n",
    "            \n",
    "            # Start of run 2, reinitialise v0\n",
    "            if t == int(Ntrials/2): \n",
    "                vt[t] = v0r\n",
    "            \n",
    "            # if hit, recieves fb\n",
    "            elif hits[t-1] == 1:\n",
    "                # Compute prediction error\n",
    "                pe[t-1] = fbs[t-1] - vt[t-1]\n",
    "                # Compute new vt and fill in \n",
    "                vt[t] = vt[t-1] + alpha * pe[t-1]\n",
    "            \n",
    "            # if no hit, no fb\n",
    "            elif hits[t-1] == 0:\n",
    "                # vt does not change \n",
    "                vt[t] = vt[t-1] \n",
    "        \n",
    "        vt_all_cues[cue] = vt\n",
    "        pe_all_cues[cue] = pe\n",
    "    \n",
    "    return vt_all_cues, pe_all_cues, []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de01ffc-f48f-4034-bc84-457da34ccc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescorla_wagner(fbs_all_cues, trialNo_all_cues, param_values, param_names, isHit_all_cues):\n",
    "    \n",
    "    # Free parameters\n",
    "    v0 = param_values[param_names.index('v0')]\n",
    "    alpha = param_values[param_names.index('alpha')]\n",
    "    \n",
    "    # Initialise empty dicitonnary\n",
    "    vt_all_cues = dict.fromkeys(fbs_all_cues.keys())\n",
    "    pe_all_cues = dict.fromkeys(fbs_all_cues.keys())\n",
    "    \n",
    "    # Iterate over cues\n",
    "    for cue, fbs, hits in zip(fbs_all_cues.keys(), fbs_all_cues.values(), isHit_all_cues.values()):\n",
    "                \n",
    "        # Initialise vector of values\n",
    "        vt = np.empty(len(fbs))\n",
    "        vt.fill(np.nan)\n",
    "        \n",
    "        # Initialise vector of PEs\n",
    "        pe = np.empty(len(fbs))\n",
    "        pe.fill(np.nan)\n",
    "        \n",
    "        # Fill in prior\n",
    "        # If want specific prior per cue, check value of cue\n",
    "        vt[0] = v0\n",
    "        \n",
    "        # Iterate to fill in vector\n",
    "        for t in range(1,len(vt)):\n",
    "                        \n",
    "            # if hit, recieves fb\n",
    "            if hits[t-1] == 1:\n",
    "                            \n",
    "                # Compute prediction error\n",
    "                pe[t-1] = fbs[t-1] - vt[t-1]\n",
    "\n",
    "                # Compute new vt and fill in \n",
    "                vt[t] = vt[t-1] + alpha * pe[t-1]\n",
    "                \n",
    "            # if no hit, no fb\n",
    "            elif hits[t-1] == 0:\n",
    "                # vt does not change \n",
    "                vt[t] = vt[t-1] \n",
    "        \n",
    "        vt_all_cues[cue] = vt\n",
    "        pe_all_cues[cue] = pe\n",
    "    \n",
    "    return vt_all_cues, pe_all_cues, []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada59fb5-5434-4a87-b449-2db647a76606",
   "metadata": {},
   "source": [
    "# Decision functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490cf7e3-8ffe-4fc2-80fb-4a48d3b7e34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_softmax_shrinking_2_press_bias(vt_all_cues, trialNo_all_cues, param_values, param_names):\n",
    "    \n",
    "    # Free parameters\n",
    "    beta = param_values[param_names.index('beta')]\n",
    "    pi = param_values[param_names.index('pi')]\n",
    "    pi_t = param_values[param_names.index('pi_t')]\n",
    "    \n",
    "    # Initialise empty dicitonnary\n",
    "    p_hit_all_cues = dict.fromkeys(vt_all_cues.keys())\n",
    "    \n",
    "    # Iterate over cues\n",
    "    for cue, vt in vt_all_cues.items():\n",
    "        \n",
    "        # Extract trials for this cue\n",
    "        trials = trialNo_all_cues[cue]\n",
    "\n",
    "        # Reinitialise each trial of run 2 (above 56)\n",
    "        trials_per_run_lst = []\n",
    "        run_size = 56\n",
    "        for trial in trials:\n",
    "            if trial > run_size:\n",
    "                trials_per_run_lst.append(trial-run_size)\n",
    "            else:\n",
    "                trials_per_run_lst.append(trial)\n",
    "\n",
    "        # Convert to array\n",
    "        trials_per_run = np.array(trials_per_run_lst)\n",
    "        \n",
    "        # Compute shrinking factor = (N-t)/N\n",
    "        shrink = (run_size - trials_per_run)/run_size\n",
    "\n",
    "        # Higher press bias with small trial numbers\n",
    "        x = beta * (vt + pi + pi_t*shrink)\n",
    "        \n",
    "        try:\n",
    "            p_hit =  np.exp(x)/(np.exp(x)+1)\n",
    "        except RuntimeWarning:\n",
    "            # to avoid overflow errors\n",
    "            expon_bound = 700\n",
    "            p_hit = [1 if el>expon_bound else (np.exp(el)/(np.exp(el)+1)) for el in x]\n",
    "            \n",
    "        p_hit_all_cues[cue] = p_hit\n",
    "    \n",
    "    return p_hit_all_cues, []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6b67ec59-d3ca-406a-afc2-fa9f3d835064",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_softmax_shrinking_press_bias(vt_all_cues, trialNo_all_cues, param_values, param_names):\n",
    "    \n",
    "    # Free parameters\n",
    "    beta = param_values[param_names.index('beta')]\n",
    "    pi_t = param_values[param_names.index('pi_t')]\n",
    "    \n",
    "    # Initialise empty dicitonnary\n",
    "    p_hit_all_cues = dict.fromkeys(vt_all_cues.keys())\n",
    "    shrinking_pi_all_cues = dict.fromkeys(vt_all_cues.keys())\n",
    "    \n",
    "    # Iterate over cues\n",
    "    for cue, vt in vt_all_cues.items():\n",
    "        \n",
    "        # Extract trials for this cue\n",
    "        trials = trialNo_all_cues[cue]\n",
    "\n",
    "        # Reinitialise each trial of run 2 (above 56)\n",
    "        trials_per_run_lst = []\n",
    "        run_size = 56\n",
    "        for trial in trials:\n",
    "            if trial > run_size:\n",
    "                trials_per_run_lst.append(trial-run_size)\n",
    "            else:\n",
    "                trials_per_run_lst.append(trial)\n",
    "\n",
    "        # Convert to array\n",
    "        trials_per_run = np.array(trials_per_run_lst)\n",
    "        \n",
    "        # Compute shrinking factor = (N-t)/N\n",
    "        shrink = (run_size - trials_per_run)/run_size\n",
    "\n",
    "        # Higher press bias with small trial numbers\n",
    "        # shrinking_pi = shrink * pi_t\n",
    "        shrinking_pi = pi_t ** trials_per_run\n",
    "        x = beta * (vt + shrinking_pi)\n",
    "        \n",
    "        try:\n",
    "            p_hit =  np.exp(x)/(np.exp(x)+1)\n",
    "            \n",
    "        except RuntimeWarning:\n",
    "            # to avoid overflow errors\n",
    "            expon_bound = 700\n",
    "            p_hit = [1 if el>expon_bound else (np.exp(el)/(np.exp(el)+1)) for el in x]\n",
    "            \n",
    "        p_hit_all_cues[cue] = p_hit\n",
    "        shrinking_pi_all_cues[cue] = shrinking_pi\n",
    "    \n",
    "    return p_hit_all_cues, shrinking_pi_all_cues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b5c942e6-0f1c-43ef-a1dc-92bf979146d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_softmax_press_bias(vt_all_cues, trialNo_all_cues, param_values, param_names):\n",
    "    \n",
    "    # Free parameters\n",
    "    beta = param_values[param_names.index('beta')]\n",
    "    pi = param_values[param_names.index('pi')]\n",
    "    \n",
    "    # Initialise empty dicitonnary\n",
    "    p_hit_all_cues = dict.fromkeys(vt_all_cues.keys())\n",
    "    \n",
    "    # Iterate over cues\n",
    "    for cue, vt in vt_all_cues.items():\n",
    "                \n",
    "        x = beta * (vt + pi)\n",
    "        \n",
    "        try:\n",
    "            p_hit =  np.exp(x)/(np.exp(x)+1)\n",
    "        except RuntimeWarning:\n",
    "            # to avoid overflow errors\n",
    "            expon_bound = 700\n",
    "            p_hit = [1 if el>expon_bound else (np.exp(el)/(np.exp(el)+1)) for el in x]\n",
    "            \n",
    "        p_hit_all_cues[cue] = p_hit\n",
    "    \n",
    "    return p_hit_all_cues, []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcba95aa-2edd-4525-a7db-f35785054118",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_softmax(vt_all_cues, trialNo_all_cues, param_values, param_names):\n",
    "    \n",
    "    # Free parameters\n",
    "    beta = param_values[param_names.index('beta')]\n",
    "    \n",
    "    # Initialise empty dicitonnary\n",
    "    p_hit_all_cues = dict.fromkeys(vt_all_cues.keys())\n",
    "    \n",
    "    # Iterate over cuesss\n",
    "    for cue, vt in vt_all_cues.items():\n",
    "                \n",
    "        x = beta*vt\n",
    "        \n",
    "        try:\n",
    "            p_hit =  np.exp(x)/(np.exp(x)+1)\n",
    "            \n",
    "        except RuntimeWarning:\n",
    "            # to avoid overflow errors\n",
    "            expon_bound = 700\n",
    "            p_hit = [1 if el>expon_bound else (np.exp(el)/(np.exp(el)+1)) for el in x]\n",
    "            \n",
    "        p_hit_all_cues[cue] = p_hit\n",
    "    \n",
    "    return p_hit_all_cues, []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738824ad-68fd-463a-894b-803317e22398",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_softmax_scipy(vt_all_cues, trialNo_all_cues, param_values, param_names):\n",
    "    \n",
    "    # Free parameters\n",
    "    beta = param_values[param_names.index('beta')]\n",
    "    \n",
    "    # Initialise empty dictionnary\n",
    "    p_hit_all_cues = dict.fromkeys(vt_all_cues.keys())\n",
    "\n",
    "    for cue, vts in vt_all_cues.items():\n",
    "        p_hit = []\n",
    "        for vt in vts:\n",
    "            Q_hit = vt * beta\n",
    "            Q_miss = 0\n",
    "            probs = scipy.special.softmax([Q_hit, Q_miss])\n",
    "            p_hit.append(probs[0])\n",
    "\n",
    "        p_hit_all_cues[cue] = np.array(p_hit)\n",
    "    \n",
    "    return p_hit_all_cues, []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd00c6b-e18d-4c1e-ba95-e08c07f3e3c1",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e7dc1cf5-494f-49bb-99da-1dc978befa28",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    \n",
    "    def __init__(self, mod_name, value_fct, dec_fct, param_names):\n",
    "        self.value_fct = value_fct\n",
    "        self.dec_fct = dec_fct\n",
    "        self.param_names = param_names\n",
    "        self.mod_name = mod_name\n",
    "        self.param_values = []\n",
    "        self.gen_param_values = []\n",
    "        self.values = []\n",
    "        self.p_hit = []\n",
    "        self.cue_nLLs = []\n",
    "        self.total_cue_nLL = []\n",
    "        self.fbs_all_cues = []\n",
    "        self.isHit_all_cues = []\n",
    "        self.nLL = []\n",
    "        self.ID = []  \n",
    "        self.Ntrials = []  \n",
    "        self.PEs = []\n",
    "        self.shrink_pi = []\n",
    "        self.shrink_alpha = []\n",
    "    \n",
    "    def set_param_values(self, param_values):\n",
    "        self.param_values = param_values\n",
    "            \n",
    "    def set_data(self, ID, fbs_all_cues, isHit_all_cues, trialNo_all_cues):\n",
    "        self.ID = ID\n",
    "        self.fbs_all_cues = fbs_all_cues\n",
    "        self.isHit_all_cues = isHit_all_cues\n",
    "        self.trialNo_all_cues = trialNo_all_cues\n",
    "            \n",
    "    def compute_ll_per_cue(self, p_hit_all_cues, isHit_all_cues):\n",
    "        \n",
    "        # Initialise empty dicitonnary\n",
    "        nLLs_all_cues = dict.fromkeys(p_hit_all_cues.keys())\n",
    "        total_nLL_all_cues = dict.fromkeys(p_hit_all_cues.keys())\n",
    "        Ntrials_per_cue = dict.fromkeys(p_hit_all_cues.keys())\n",
    "        \n",
    "        # Iterate over cues\n",
    "        for cue, p_hit in p_hit_all_cues.items():\n",
    "            isHit = isHit_all_cues[cue]\n",
    "            # compute likelihoods of choices\n",
    "            ll_choice = []\n",
    "            almost_zero = np.finfo(float).tiny\n",
    "            for ind, hit in enumerate(isHit):\n",
    "                if hit==1:\n",
    "                    p_ =  p_hit[ind]\n",
    "                else:\n",
    "                    p_ =  1-p_hit[ind]\n",
    "                    \n",
    "                ll_choice.append(almost_zero if p_<almost_zero else p_)\n",
    "                             \n",
    "            nLLs = -np.log(ll_choice)\n",
    "            nLLs_all_cues[cue] = nLLs\n",
    "            total_nLL_all_cues[cue] = sum(nLLs)\n",
    "            Ntrials_per_cue[cue] = len(nLLs)\n",
    "            \n",
    "        return total_nLL_all_cues, nLLs_all_cues, Ntrials_per_cue\n",
    "    \n",
    "    def fit(self, param_lower_bound, param_upper_bound, n_iterations, method='Powell'):\n",
    "        \n",
    "        # compute sequence of parameter bounds\n",
    "        bounds = []\n",
    "        for low, up in zip(param_lower_bound, param_upper_bound):\n",
    "            bounds.append([low,up])\n",
    "                \n",
    "        # init\n",
    "        mat_min_nLL=[]\n",
    "        mat_best_params=[]\n",
    "        \n",
    "        for i in range(0,n_iterations):\n",
    "            \n",
    "            # define the starting point as a random sample from the domain\n",
    "            initial_guess = np.array(param_lower_bound) + np.random.rand(len(param_lower_bound)) * (np.array(param_upper_bound) - np.array(param_lower_bound))\n",
    "\n",
    "            # find the min likelihood \n",
    "            result = minimize(self.compute_nLL, initial_guess, method = method, bounds = bounds, \n",
    "                              options={'xtol': 1e-8, 'disp': False})\n",
    "\n",
    "            # store min_nLL and parameters\n",
    "            mat_min_nLL.append(result.fun)\n",
    "            mat_best_params.append(result.x)\n",
    "\n",
    "        # Find best params\n",
    "        ind = np.argmin(mat_min_nLL)\n",
    "        best_params = mat_best_params[ind]\n",
    "\n",
    "        # Compute best LL and store\n",
    "        nLL = self.compute_nLL(best_params)   \n",
    "        \n",
    "        \n",
    "    def simulate_behaviour(self, fbs_all_cues, trialNo_all_cues, param_values, param_names):\n",
    "    \n",
    "        # Store parameter values used for behaviour generation\n",
    "        self.gen_param_values = param_values\n",
    "\n",
    "        # compute expected values\n",
    "        vt_all_cues, pe_all_cues = self.value_fct(fbs_all_cues, trialNo_all_cues, param_values, param_names, self.isHit_all_cues)\n",
    "\n",
    "        # compute hit probability\n",
    "        p_hit_all_cues  = self.dec_fct(vt_all_cues, trialNo_all_cues, param_values, param_names)\n",
    "\n",
    "        # Simulate hits (1 or 0)\n",
    "        isHit_all_cues = {}\n",
    "\n",
    "        for cue, p_hits in p_hit_all_cues.items():\n",
    "\n",
    "            isHit = []\n",
    "\n",
    "            trials_per_cue = len(p_hits)\n",
    "\n",
    "            # Sample randomly\n",
    "            rand_samples = np.random.uniform(low=0.0, high=1.0, size=trials_per_cue)\n",
    "            for rand_sample, p_hit in zip(rand_samples, p_hits):\n",
    "                if rand_sample <= p_hit:\n",
    "                    isHit.append(1)\n",
    "                else:\n",
    "                    isHit.append(0)\n",
    "\n",
    "            # Concat all cues\n",
    "            isHit_all_cues[cue] = isHit\n",
    "\n",
    "        # Store \n",
    "        self.set_data('', fbs_all_cues, isHit_all_cues, trialNo_all_cues)\n",
    "                \n",
    "    \n",
    "    def compute_nLL(self, param_values):\n",
    "        \n",
    "        fbs_all_cues = self.fbs_all_cues\n",
    "        isHit_all_cues = self.isHit_all_cues\n",
    "        trialNo_all_cues = self.trialNo_all_cues\n",
    "        \n",
    "        # set parameter values\n",
    "        self.set_param_values(param_values)\n",
    "\n",
    "        # compute expected values\n",
    "        vt_all_cues, pe_all_cues, shrinking_alpha_all_cues = self.value_fct(fbs_all_cues, self.trialNo_all_cues, self.param_values, self.param_names, isHit_all_cues)\n",
    "        \n",
    "        # compute hit probability\n",
    "        p_hit_all_cues, shrinking_pi_all_cues  = self.dec_fct(vt_all_cues, self.trialNo_all_cues, self.param_values, self.param_names)\n",
    "        \n",
    "        # compute nLL per cue\n",
    "        total_nLL_all_cues, nLLs_all_cues, Ntrials_per_cue = self.compute_ll_per_cue(p_hit_all_cues, isHit_all_cues)\n",
    "        \n",
    "        # compute total neg LL (sum over cues, i.e. multiply likelihoods)\n",
    "        nLL = sum(total_nLL_all_cues.values())\n",
    "        \n",
    "        # save total number of trials\n",
    "        Ntrials = sum(Ntrials_per_cue.values())\n",
    "        \n",
    "        # Set values\n",
    "        self.v = vt_all_cues\n",
    "        self.p_hit = p_hit_all_cues\n",
    "        self.cue_nLLs = nLLs_all_cues\n",
    "        self.total_cue_nLL = total_nLL_all_cues\n",
    "        self.nLL = nLL\n",
    "        self.Ntrials = Ntrials\n",
    "        self.PEs = pe_all_cues\n",
    "        self.shrink_pi = shrinking_pi_all_cues\n",
    "        self.shrink_alpha = shrinking_alpha_all_cues\n",
    "        \n",
    "        return nLL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3878fb07-a01b-475a-92cb-f4186e5b7c67",
   "metadata": {},
   "source": [
    "# Ploting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8cb45fc9-9b8a-4241-a655-8927d15f7251",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_correlation(title, x, y, data, ax, text_pos, xlabel, ylabel, xlim, ylim):\n",
    "        \n",
    "    # Initialise figue\n",
    "    ax.set_title(title, fontsize = 22)\n",
    "\n",
    "    # Scatter plot\n",
    "    sns.scatterplot( x = x, y = y, data = data, ax = ax);\n",
    "\n",
    "    # Linear regression line\n",
    "    sns.regplot(x = x, y = y, data = data, ax = ax);\n",
    "    \n",
    "    # Plot horizontal line\n",
    "    ax.axhline(y=0, color='k', linestyle=':')\n",
    "\n",
    "    # Compute correlation stats (r and p values)\n",
    "    r, p = pearsonr(data[x], data[y])\n",
    "    \n",
    "    # Write stats on fig\n",
    "    if p<0.01:\n",
    "        ax.text(text_pos[0], text_pos[1], 'r={:.2f} \\np<0.01'.format(r, p), transform=ax.transAxes, fontsize=16)\n",
    "    else:    \n",
    "        ax.text(text_pos[0], text_pos[1], 'r={:.2f} \\np={:.2g}'.format(r, p), transform=ax.transAxes, fontsize=16)\n",
    "    \n",
    "    # Properties\n",
    "    ax.set_ylabel(ylabel, fontsize=15)\n",
    "    ax.set_ylim(bottom=ylim[0], top=ylim[1])\n",
    "    \n",
    "    ax.set_xlabel(xlabel, fontsize=15)\n",
    "    ax.set_xlim(left=xlim[0], right=xlim[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f36fce68-ee9e-4a05-9bfe-b6377fc8b4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_behaviour_allcues(mod1, window_size, save_fig=False):\n",
    "    \n",
    "    # User folder for running average data\n",
    "    user_folder = 'data/user_' + mod1.ID + '/cue_hit_miss_perc/'\n",
    "    \n",
    "    # Timepoints\n",
    "    N_trials = 28\n",
    "    N_iter = int(N_trials/window_size)\n",
    "    timepoints = ['t'+ str(t+1) for t in range(N_iter)]\n",
    "    xt = (np.arange(len(timepoints))+1)*window_size\n",
    "\n",
    "    fig, axs = plt.subplots(4, 1, figsize=(10,10), facecolor='white')\n",
    "    plt.subplots_adjust(hspace=0.5)\n",
    "\n",
    "    cues = ['HR', 'HP', 'LR', 'LP']\n",
    "\n",
    "    for i,cue in enumerate(cues):\n",
    "\n",
    "        ax = axs[i]\n",
    "\n",
    "        # Extract data for plotting\n",
    "        p_hit_model = mod1.p_hit[cue]\n",
    "        vt_model = mod1.v[cue]\n",
    "        isHit = mod1.isHit_all_cues[cue]\n",
    "        fbs = mod1.fbs_all_cues[cue]\n",
    "        hit_miss_perc = pd.read_pickle(user_folder + 'hit_miss_perc_' + cue + '_window_size_' + str(window_size) + '.pkl')\n",
    "\n",
    "        # Plot fbs\n",
    "        height_fb = 1.13\n",
    "        x = [ind+1 for ind, el in enumerate(fbs) if el == 5]\n",
    "        l_fb_5 = ax.scatter(x, height_fb * np.ones(len(x)), c='green', alpha=0.9)\n",
    "        x = [ind+1 for ind, el in enumerate(fbs) if el == 1]\n",
    "        l_fb_1 = ax.scatter(x, height_fb * np.ones(len(x)), c='green', alpha=0.1)\n",
    "        x = [ind+1 for ind, el in enumerate(fbs) if el == -1]\n",
    "        l_fb_m1 = ax.scatter(x, height_fb * np.ones(len(x)), c='red', alpha=0.1)\n",
    "        x = [ind+1 for ind, el in enumerate(fbs) if el == -5]\n",
    "        l_fb_m5 = ax.scatter(x, height_fb * np.ones(len(x)), c='red', alpha=0.9)\n",
    "\n",
    "        # Plot hits (marker)\n",
    "        height_hit = 1.2\n",
    "        x_hit = [ind+1 for ind, el in enumerate(isHit) if el == 1]\n",
    "        l_hits = ax.scatter(x_hit, height_hit * np.ones(len(x_hit)), c='black', alpha=1, marker='v')\n",
    "\n",
    "        # Plot hit perc (running average)\n",
    "        l_wind_m, = ax.plot(xt, hit_miss_perc.loc['hit'], '.-', color='darkorange', alpha=1)\n",
    "\n",
    "        # Plot probability of hits (from model)\n",
    "        l_p_h_mod, = ax.plot(list(range(1,len(p_hit_model)+1)), p_hit_model)\n",
    "\n",
    "        # Legend\n",
    "        ax.legend([l_wind_m, l_p_h_mod], \n",
    "                  ['Hit running average', \n",
    "                   'Hit model probability (alpha=' + str(round(mod1.param_values[1],2))+\n",
    "                   ', v0='+ str(round(mod1.param_values[0],2))+\n",
    "                   ', beta='+ str(round(mod1.param_values[2],2)) + ')'],\n",
    "                  frameon=False)\n",
    "\n",
    "        # Labels etc \n",
    "        ax.set_ylim([0,1.24])\n",
    "\n",
    "        # Title \n",
    "        ax.set_title(cue)\n",
    "\n",
    "        # Plot vertical grid\n",
    "        ax.grid(axis=\"x\", alpha=0.1)\n",
    "\n",
    "        # Plot horizontal line at 0\n",
    "        ax.plot(np.arange(-1,30), np.zeros(len(np.arange(-1,30))), 'k--', alpha=0.5, linewidth=1.0)\n",
    "\n",
    "        # x-axis (trials)\n",
    "        x_ticks = list(range(1,len(fbs)+1))\n",
    "        ax.set_xlim(x_ticks[0]-1,x_ticks[-1]+1)\n",
    "        ax.set_xticks(x_ticks)\n",
    "        ax.set_xlabel('', fontsize = 18)\n",
    "\n",
    "    \n",
    "    if save_fig:\n",
    "        user_fig = 'data/user_' + mod1.ID + '/behav_' + mod1.mod_name + '.png'\n",
    "        plt.savefig(user_fig)\n",
    "        plt.close() \n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "35358520-9aa4-4336-bf96-a7c32c92454b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_parameters(data_mod, param_names):\n",
    "    \n",
    "    Nparam = len(param_names)\n",
    "    \n",
    "    if Nparam<=3:\n",
    "        f, axs = plt.subplots(1, Nparam, figsize=(Nparam*6, 5))\n",
    "    elif Nparam==4:\n",
    "        f, axs = plt.subplots(2, 2, figsize=(2*6, 2*5))\n",
    "        axs = axs.reshape(-1)\n",
    "    else:\n",
    "        f, axs = plt.subplots(2, 3, figsize=(3*6, 2*5))\n",
    "        axs = axs.reshape(-1)\n",
    "        \n",
    "    plt.subplots_adjust(hspace = 0.3)\n",
    "        \n",
    "    pal = sns.color_palette(n_colors=1)\n",
    "\n",
    "    for ax, param in zip(axs, param_names):\n",
    "\n",
    "        y = data_mod[param].tolist()\n",
    "\n",
    "        # plot clouds\n",
    "        pt.half_violinplot(ax=ax, x = y, palette = pal, bw = .2, cut = 0., scale = \"area\", width = .6, inner = None, orient = 'h')\n",
    "\n",
    "        # add rain\n",
    "        sns.stripplot(ax=ax, x = y, palette = pal, edgecolor = \"white\", size = 5, jitter = 1, zorder = 0, orient = 'h', alpha=.35)\n",
    "\n",
    "        sns.boxplot(x = y, saturation=1, showfliers=False,\n",
    "                width=0.15, boxprops={'zorder': 3, 'facecolor': 'none'}, ax=ax)\n",
    "\n",
    "        # Makeup\n",
    "        ax.set_title('Parameter: ' + param, fontsize=18)\n",
    "        ax.set_xlabel('Best fit parameter value', fontsize=16)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e77d5f4-126c-4f04-91da-01acfc5de472",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fig_modelpred_on_behav(ev_per_trial, p_hit_per_trial, all_users_folder):\n",
    "\n",
    "    # Timepoints\n",
    "    window_size = 16\n",
    "    N_trials = 112\n",
    "    timepoints = ['t'+ str(t+1) for t in range(int(N_trials/window_size))]\n",
    "\n",
    "    # Load behaviour and compute stats\n",
    "    hit_perc_per_t = pd.read_pickle(all_users_folder + 'hit_perc_per_t/hit_perc_per_t_w' + str(window_size) + '.pkl');\n",
    "    hit_perc_per_t.drop('ID', axis=1, inplace=True);\n",
    "    stats_hits_perc_per_t = hit_perc_per_t.groupby('Code').agg(['mean', 'var']).T.swaplevel(axis=0);\n",
    "\n",
    "    # Load model predictions and compute stats\n",
    "    ev_per_trial.drop('ID', axis=1, inplace=True);\n",
    "    stats_ev_per_trial = ev_per_trial.groupby('Cue').agg(['mean', 'var']).T.swaplevel(axis=0)\n",
    "    stats_ev_per_trial.columns = 'Cue_'+stats_ev_per_trial.columns\n",
    "\n",
    "    p_hit_per_trial.drop('ID', axis=1, inplace=True);\n",
    "    stats_p_hit_per_trial = p_hit_per_trial.groupby('Cue').agg(['mean', 'var']).T.swaplevel(axis=0)\n",
    "    stats_p_hit_per_trial.columns = 'Cue_'+stats_p_hit_per_trial.columns\n",
    "\n",
    "    # Plot\n",
    "    f, axs = plt.subplots(2, 1, figsize=(10, 6), dpi=80)\n",
    "    plt.subplots_adjust(hspace = 0.4)\n",
    "\n",
    "    x_mod = np.arange(len(stats_ev_per_trial.loc['mean']))+1\n",
    "    x_behav = np.arange(len(timepoints))*4+4\n",
    "\n",
    "    for cue, color, alpha in zip(['Cue_HP', 'Cue_LP', 'Cue_LR', 'Cue_HR'], ['red', 'red', 'green', 'green'], [0.6, 0.3, 0.3, 0.6]):\n",
    "        # Hit probabilites\n",
    "        m=axs[0].plot(x_mod, stats_p_hit_per_trial.loc['mean'][cue], '.-', color=color, alpha=alpha);\n",
    "        # Behaviour: sliding average\n",
    "        b=axs[0].plot(x_behav, stats_hits_perc_per_t.loc['mean'][cue], '.-', color='gray', alpha=alpha);\n",
    "        # Expected values\n",
    "        m=axs[1].plot(x_mod, stats_ev_per_trial.loc['mean'][cue], '.-', color=color, alpha=alpha);\n",
    "\n",
    "    for ax in axs:\n",
    "        ax.grid(axis='x', color='0.95');\n",
    "        ax.set_xticks(x_mod);\n",
    "    \n",
    "    axs[0].set_title('Model probability of hit', fontsize=16);\n",
    "    axs[1].set_title('Model expected values', fontsize=16);\n",
    "    \n",
    "    axs[0].set_ylabel(\"Hit [%]\", fontsize=16);\n",
    "    axs[1].set_ylabel(\"Values\", fontsize=16);\n",
    "    \n",
    "    axs[0].set_ylim([0,1]);\n",
    "    axs[1].set_ylim([-3,3]);\n",
    "    \n",
    "    axs[0].legend(b, {'Behaviour'})\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd08ec75-c910-4087-a9df-dd3d6ad6dd83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2464dd-b03f-464a-9d2c-6bb8921a6c02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59a5c5e-1b4c-4ff2-8451-8a297ddc7b22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
