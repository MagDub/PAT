{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "29522f36-0e68-4c36-aebc-18d17e71bf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pickle\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "941dced2-1ea4-482c-b18d-f788eddcec59",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = '../2_PAT/'\n",
    "files = os.listdir(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "83a797a1-a53b-4c46-81b4-0ce962ef9217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170\n"
     ]
    }
   ],
   "source": [
    "# Make list of participants\n",
    "IDs = []\n",
    "for file in files:\n",
    "    IDs.append(file.split('_')[1].split('-')[0])\n",
    "\n",
    "uniqueIDs = list(set(IDs))\n",
    "uniqueIDs.sort()\n",
    "N_part = len(uniqueIDs)\n",
    "print(N_part)\n",
    "\n",
    "# Save uniqueIDs list as pickle\n",
    "with open('uniqueIDs.pkl', 'wb') as f:\n",
    "    pickle.dump(uniqueIDs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7c8dca5-c098-4572-8617-87fa77f38367",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_2df(file_name):\n",
    "    \n",
    "    ''' \n",
    "    Creates 2 data frames from the inputed log file \n",
    "    '''\n",
    "    \n",
    "    # Read log file\n",
    "    with open(file_name, newline = '') as file_:                                                                                          \n",
    "        file_reader = csv.reader(file_, delimiter='\\t')\n",
    "        text = list(file_reader)\n",
    "    \n",
    "    table1_index = text.index(['Subject', 'Trial', 'Event Type', 'Code', 'Time', 'TTime', 'Uncertainty', 'Duration', 'Uncertainty', 'ReqTime', 'ReqDur', 'Stim Type', 'Pair Index'])\n",
    "    table2_index = text.index(['Event Type', 'Code', 'Type', 'Response', 'RT', 'RT Uncertainty', 'Time', 'Uncertainty', 'Duration', 'Uncertainty', 'ReqTime', 'ReqDur'])\n",
    "    \n",
    "    df1 = pd.DataFrame.from_records(text[table1_index+1:table2_index])\n",
    "    df1.columns = text[table1_index]\n",
    "    df1.dropna(how='all', inplace=True)\n",
    "\n",
    "    df2 = pd.DataFrame.from_records(text[table2_index+1::])\n",
    "    df2.columns = text[table2_index]\n",
    "    df2.dropna(how='all', inplace=True)\n",
    "    \n",
    "    return df1, df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d82cb5e4-66f9-4a7f-ae91-c4cdc3ce9f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df2(df2):\n",
    "    \n",
    "    ''' \n",
    "    Remove useless rows and columns in df2\n",
    "    '''\n",
    "        \n",
    "    # Rows: Keep only hit/miss and fb trials\n",
    "    df2new = df2.drop(df2[(df2.Code=='Fix')].index, inplace=False)\n",
    "    df2new = df2new.drop(df2new[(df2new.Code=='Instruction_Run_1')].index, inplace=False)\n",
    "    df2new = df2new.drop(df2new[(df2new.Code=='Instruction_Run_2')].index, inplace=False)\n",
    "    df2new = df2new.drop(df2new[(df2new.Code=='Wait_for_scanner')].index, inplace=False)\n",
    "    df2new = df2new.drop(df2new[(df2new.Code=='EndText')].index, inplace=False)\n",
    "\n",
    "    # Columns: Drop unimportant columns\n",
    "    df2new = df2new.drop(columns=['RT', 'RT Uncertainty', 'Uncertainty', 'ReqTime', 'ReqDur'], inplace=False)\n",
    "    \n",
    "    return df2new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87fc0a3b-6b18-4068-a530-b6fb87e10dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat_cues_fb(df2):\n",
    "    \n",
    "    ''' \n",
    "    Reformat (have cues and fb in columns instead of rows after each other)\n",
    "    '''\n",
    "    \n",
    "    df2_cues = df2[0::2]\n",
    "    df2_cues.reset_index(inplace=True)\n",
    "\n",
    "    df2_fb = df2[1::2]\n",
    "    df2_fb.reset_index(inplace=True)\n",
    "    \n",
    "    # Change names to avoid duplicates\n",
    "    df2_fb.set_axis(['FB index', 'FB Event Type', 'FB Code', 'FB Type', 'FB Response', 'FB Time', 'FB Duration', 'FB Run'], axis=1, inplace=True) \n",
    "\n",
    "    df2_new = pd.concat([df2_cues, df2_fb], axis=1)\n",
    "    \n",
    "    df2_new.reset_index(inplace=True)\n",
    "    df2_new.drop('index', axis=1, inplace=True)\n",
    "    df2_new.drop('level_0', axis=1, inplace=True)\n",
    "    df2_new.drop('FB Run', axis=1, inplace=True)\n",
    "    \n",
    "    # Make new columns\n",
    "    df2_new['isHit'] = (df2_new['Type']=='hit').astype(int)\n",
    "    df2_new['FBs'] = [int(fb.strip('FB_no')) for fb in df2_new['FB Code'].tolist()]\n",
    "    df2_new['rews'] = df2_new['isHit']*df2_new['FBs']\n",
    "    \n",
    "    # Create a trial column\n",
    "    df2_new.insert(0, \"Trial\", list(range(1,len(df2_new)+1)))\n",
    "    \n",
    "    return df2_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f12e4b7-2894-45d2-8819-62615a6ace21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_fb_by_cue(df2):\n",
    "    \n",
    "    ''' \n",
    "    Count the recieved fb split in cue condition\n",
    "    '''\n",
    "    \n",
    "    # Create an empty df with all columns and rows names\n",
    "    FB_values = ['FB_1','FB_-1','FB_5','FB_-5','FB_no_1','FB_no_-1','FB_no_5','FB_no_-5']\n",
    "    cue_values = list(sorted(set(df2['Code'])))\n",
    "    big_df = pd.DataFrame([],columns=cue_values, index=FB_values)\n",
    "\n",
    "    for cue_value in cue_values:\n",
    "\n",
    "        # for each cue condition create df with the counts\n",
    "        small_df = df2[df2['Code']==cue_value]['FB Code'].value_counts().to_frame(cue_value)\n",
    "\n",
    "        # fill in the df\n",
    "        big_df = big_df.combine_first(small_df)\n",
    "\n",
    "    df2_count = big_df.transpose()\n",
    "    df2_count.reset_index(level=0, inplace=True)\n",
    "    \n",
    "    return df2_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16790a2f-61c9-4eb3-94ea-a45aa147282a",
   "metadata": {},
   "source": [
    "# Reformat data for each user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "592c1c4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Clean and save data for each user\n",
    "for ID in uniqueIDs: \n",
    "\n",
    "    # Creates user folder and file if does not already exist\n",
    "    user_folder = 'data/user_' + ID + '/'\n",
    "    isExist = os.path.exists(user_folder)\n",
    "    if not isExist:\n",
    "        os.makedirs(user_folder)\n",
    "\n",
    "        print(ID)\n",
    "\n",
    "        # Extract data into 2 dfs (for run1 and run2)\n",
    "        df1_run1, df2_run1 = create_2df(folder + 'MARS_' + ID + '-PA_europ.log')\n",
    "        df1_run2, df2_run2 = create_2df(folder + 'MARS_' + ID + '-PA_europ1.log') \n",
    "\n",
    "        # Focus on df2 becase has hit/miss/FB info\n",
    "\n",
    "        # Clean (remove useless rows and cols)\n",
    "        df2_run1_c = clean_df2(df2_run1)\n",
    "        df2_run2_c = clean_df2(df2_run2)\n",
    "\n",
    "        # Add run information \n",
    "        df2_run1_c['Run'] = 1\n",
    "        df2_run2_c['Run'] = 2\n",
    "\n",
    "        # Concatenate\n",
    "        df2_c = pd.concat([df2_run1_c, df2_run2_c])\n",
    "\n",
    "        # Reformat (have fb in a column instead of row below)\n",
    "        df2_cf = reformat_cues_fb(df2_c)\n",
    "\n",
    "        # Save df2_cf as pickle\n",
    "        df2_cf.to_pickle(user_folder + 'df2_cf.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127ecc2e-98f2-4366-8d31-7c57b0fd072a",
   "metadata": {},
   "source": [
    "# Concatenate all users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "66f98fea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "001\n",
      "003\n",
      "006\n",
      "007\n",
      "008\n",
      "009\n",
      "010\n",
      "012\n",
      "014\n",
      "023\n",
      "028\n",
      "032\n",
      "033\n",
      "034\n",
      "035\n",
      "036\n",
      "038\n",
      "044\n",
      "045\n",
      "049\n",
      "050\n",
      "054\n",
      "055\n",
      "057\n",
      "058\n",
      "060\n",
      "072\n",
      "073\n",
      "075\n",
      "076\n",
      "077\n",
      "078\n",
      "080\n",
      "084\n",
      "085\n",
      "086\n",
      "088\n",
      "090\n",
      "093\n",
      "096\n",
      "100\n",
      "101\n",
      "103\n",
      "104\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "112\n",
      "114\n",
      "115\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "130\n",
      "132\n",
      "133\n",
      "136\n",
      "137\n",
      "138\n",
      "142\n",
      "143\n",
      "145\n",
      "147\n",
      "149\n",
      "151\n",
      "155\n",
      "158\n",
      "159\n",
      "165\n",
      "170\n",
      "172\n",
      "173\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "181\n",
      "185\n",
      "186\n",
      "187\n",
      "189\n",
      "199\n",
      "204\n",
      "207\n",
      "208\n",
      "211\n",
      "213\n",
      "217\n",
      "221\n",
      "229\n",
      "230\n",
      "236\n",
      "237\n",
      "239\n",
      "240\n",
      "244\n",
      "251\n",
      "252\n",
      "258\n",
      "259\n",
      "263\n",
      "269\n",
      "271\n",
      "280\n",
      "282\n",
      "283\n",
      "284\n",
      "286\n",
      "287\n",
      "291\n",
      "292\n",
      "293\n",
      "301\n",
      "302\n",
      "303\n",
      "306\n",
      "313\n",
      "314\n",
      "315\n",
      "319\n",
      "321\n",
      "322\n",
      "325\n",
      "326\n",
      "327\n",
      "329\n",
      "335\n",
      "336\n",
      "337\n",
      "339\n",
      "341\n",
      "345\n",
      "349\n",
      "351\n",
      "360\n",
      "361\n",
      "362\n",
      "368\n",
      "375\n",
      "376\n",
      "381\n",
      "384\n",
      "390\n",
      "391\n",
      "393\n",
      "395\n",
      "397\n",
      "400\n",
      "405\n",
      "406\n",
      "412\n",
      "413\n",
      "414\n",
      "421\n",
      "422\n",
      "423\n",
      "427\n",
      "437\n",
      "438\n",
      "440\n",
      "446\n",
      "450\n",
      "453\n",
      "462\n",
      "469\n",
      "470\n",
      "471\n"
     ]
    }
   ],
   "source": [
    "### Counts all and store in ALL COUNTS\n",
    "all_counts = pd.DataFrame([])\n",
    "\n",
    "for ID in uniqueIDs: \n",
    "    \n",
    "    # Creates all_users folder and all_counts file if does not already exist\n",
    "    all_users_folder = 'data/all_users/'\n",
    "    isExist = os.path.exists(all_users_folder)\n",
    "    if not isExist: \n",
    "        os.makedirs(all_users_folder)\n",
    "\n",
    "    print(ID)\n",
    "\n",
    "    # Load df2_cf \n",
    "    user_folder = 'data/user_' + ID + '/'\n",
    "    df2_cf = pd.read_pickle(user_folder + 'df2_cf.pkl')\n",
    "\n",
    "    ### ALL COUNTS\n",
    "    # Count fb for each cue\n",
    "    df2_count = count_fb_by_cue(df2_cf)\n",
    "\n",
    "    # Append each participant df in a big df (=all_counts)\n",
    "    tmp=df2_count.fillna(0)\n",
    "    tmp.insert(0,'ID',ID)\n",
    "    all_counts = pd.concat([all_counts, tmp])\n",
    "\n",
    "all_counts.rename(columns={\"index\": \"Cue\"}, inplace=True)\n",
    "all_counts.reset_index(inplace=True)\n",
    "all_counts.drop('index', axis=1, inplace=True)\n",
    "\n",
    "# Concatenante hit and miss to have reward columns\n",
    "for rew in ['-5', '-1', '1', '5']:\n",
    "    all_counts['R_' + rew] = all_counts['FB_' + rew]+all_counts['FB_no_' + rew]\n",
    "\n",
    "# Save all_counts as pickle\n",
    "all_counts.to_pickle(all_users_folder + 'all_counts.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7cd9849d-bdf5-42ac-a53e-3f18d7e9e220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Cue</th>\n",
       "      <th>FB_-1</th>\n",
       "      <th>FB_-5</th>\n",
       "      <th>FB_1</th>\n",
       "      <th>FB_5</th>\n",
       "      <th>FB_no_-1</th>\n",
       "      <th>FB_no_-5</th>\n",
       "      <th>FB_no_1</th>\n",
       "      <th>FB_no_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001</td>\n",
       "      <td>Cue_HP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001</td>\n",
       "      <td>Cue_HR</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001</td>\n",
       "      <td>Cue_LP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001</td>\n",
       "      <td>Cue_LR</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>003</td>\n",
       "      <td>Cue_HP</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>470</td>\n",
       "      <td>Cue_LR</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>471</td>\n",
       "      <td>Cue_HP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>471</td>\n",
       "      <td>Cue_HR</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>471</td>\n",
       "      <td>Cue_LP</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>471</td>\n",
       "      <td>Cue_LR</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>680 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID     Cue  FB_-1  FB_-5  FB_1  FB_5  FB_no_-1  FB_no_-5  FB_no_1  \\\n",
       "0    001  Cue_HP    0.0    0.0   0.0   0.0       6.0      14.0      4.0   \n",
       "1    001  Cue_HR    2.0    3.0   1.0   5.0       2.0       1.0      5.0   \n",
       "2    001  Cue_LP    0.0    1.0   0.0   0.0      10.0       9.0      4.0   \n",
       "3    001  Cue_LR    2.0    3.0   7.0   5.0       2.0       1.0      3.0   \n",
       "4    003  Cue_HP    3.0    3.0   1.0   1.0       3.0      11.0      3.0   \n",
       "..   ...     ...    ...    ...   ...   ...       ...       ...      ...   \n",
       "675  470  Cue_LR    4.0    4.0  10.0  10.0       0.0       0.0      0.0   \n",
       "676  471  Cue_HP    0.0    2.0   0.0   0.0       6.0      12.0      4.0   \n",
       "677  471  Cue_HR    4.0    3.0   3.0   7.0       0.0       1.0      3.0   \n",
       "678  471  Cue_LP    5.0    6.0   2.0   1.0       5.0       4.0      2.0   \n",
       "679  471  Cue_LR    3.0    2.0   5.0   3.0       1.0       2.0      5.0   \n",
       "\n",
       "     FB_no_5  \n",
       "0        4.0  \n",
       "1        9.0  \n",
       "2        4.0  \n",
       "3        5.0  \n",
       "4        3.0  \n",
       "..       ...  \n",
       "675      0.0  \n",
       "676      4.0  \n",
       "677      7.0  \n",
       "678      3.0  \n",
       "679      7.0  \n",
       "\n",
       "[680 rows x 10 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605f9185-50a4-4afb-89b9-c746c7c19868",
   "metadata": {},
   "source": [
    "# Hits by runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "72ec6c48-03be-4de0-b358-e9d9c92cf809",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "001\n",
      "003\n",
      "006\n",
      "007\n",
      "008\n",
      "009\n",
      "010\n",
      "012\n",
      "014\n",
      "023\n",
      "028\n",
      "032\n",
      "033\n",
      "034\n",
      "035\n",
      "036\n",
      "038\n",
      "044\n",
      "045\n",
      "049\n",
      "050\n",
      "054\n",
      "055\n",
      "057\n",
      "058\n",
      "060\n",
      "072\n",
      "073\n",
      "075\n",
      "076\n",
      "077\n",
      "078\n",
      "080\n",
      "084\n",
      "085\n",
      "086\n",
      "088\n",
      "090\n",
      "093\n",
      "096\n",
      "100\n",
      "101\n",
      "103\n",
      "104\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "112\n",
      "114\n",
      "115\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "130\n",
      "132\n",
      "133\n",
      "136\n",
      "137\n",
      "138\n",
      "142\n",
      "143\n",
      "145\n",
      "147\n",
      "149\n",
      "151\n",
      "155\n",
      "158\n",
      "159\n",
      "165\n",
      "170\n",
      "172\n",
      "173\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "181\n",
      "185\n",
      "186\n",
      "187\n",
      "189\n",
      "199\n",
      "204\n",
      "207\n",
      "208\n",
      "211\n",
      "213\n",
      "217\n",
      "221\n",
      "229\n",
      "230\n",
      "236\n",
      "237\n",
      "239\n",
      "240\n",
      "244\n",
      "251\n",
      "252\n",
      "258\n",
      "259\n",
      "263\n",
      "269\n",
      "271\n",
      "280\n",
      "282\n",
      "283\n",
      "284\n",
      "286\n",
      "287\n",
      "291\n",
      "292\n",
      "293\n",
      "301\n",
      "302\n",
      "303\n",
      "306\n",
      "313\n",
      "314\n",
      "315\n",
      "319\n",
      "321\n",
      "322\n",
      "325\n",
      "326\n",
      "327\n",
      "329\n",
      "335\n",
      "336\n",
      "337\n",
      "339\n",
      "341\n",
      "345\n",
      "349\n",
      "351\n",
      "360\n",
      "361\n",
      "362\n",
      "368\n",
      "375\n",
      "376\n",
      "381\n",
      "384\n",
      "390\n",
      "391\n",
      "393\n",
      "395\n",
      "397\n",
      "400\n",
      "405\n",
      "406\n",
      "412\n",
      "413\n",
      "414\n",
      "421\n",
      "422\n",
      "423\n",
      "427\n",
      "437\n",
      "438\n",
      "440\n",
      "446\n",
      "450\n",
      "453\n",
      "462\n",
      "469\n",
      "470\n",
      "471\n"
     ]
    }
   ],
   "source": [
    "### Counts all and store in ALL COUNTS (by run)\n",
    "all_counts_R = pd.DataFrame([])\n",
    "\n",
    "df2_count_Rindiv = {}\n",
    "\n",
    "for ID in uniqueIDs: \n",
    "\n",
    "    print(ID)\n",
    "\n",
    "    # Load df2_cf \n",
    "    user_folder = 'data/user_' + ID + '/'\n",
    "    df2_cf = pd.read_pickle(user_folder + 'df2_cf.pkl')\n",
    "    \n",
    "    ### ALL COUNTS by run\n",
    "    N_runs = 2\n",
    "    for run_no in range(1, N_runs+1):\n",
    "        df2_count_Rindiv[str(run_no)] = count_fb_by_cue(df2_cf[df2_cf['Run']==run_no]).fillna(0)\n",
    "        df2_count_Rindiv[str(run_no)].insert(0, 'Run', run_no)\n",
    "        df2_count_Rindiv[str(run_no)].insert(0, 'ID', ID)\n",
    "    \n",
    "    # Concat\n",
    "    tmp = pd.concat([df for df in df2_count_Rindiv.values()])\n",
    "    all_counts_R = pd.concat([all_counts_R, tmp])\n",
    "    \n",
    "all_counts_R.rename(columns={\"index\": \"Cue\"}, inplace=True)\n",
    "all_counts_R.reset_index(inplace=True)\n",
    "all_counts_R.drop('index', axis=1, inplace=True)\n",
    "\n",
    "# Concatenante hit and miss to have reward columns\n",
    "for rew in ['-5', '-1', '1', '5']:\n",
    "    all_counts_R['R_' + rew] = all_counts_R['FB_' + rew]+all_counts_R['FB_no_' + rew]\n",
    "\n",
    "# Save all_counts_R as pickle\n",
    "all_counts_R.to_pickle(all_users_folder + 'all_counts_R.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ed3bc6-2a2e-41d8-acfa-14866fa8efd5",
   "metadata": {},
   "source": [
    "# Split by half runs (= blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95881d6b-9219-4b27-8c58-9f2d0480458e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nblocks_per_run = 4\n",
    "\n",
    "all_counts_B = pd.DataFrame([])\n",
    "df2_count_Bindiv = {}\n",
    "\n",
    "for ID in uniqueIDs: \n",
    "\n",
    "    # Load df2_cf \n",
    "    user_folder = 'data/user_' + ID + '/'\n",
    "    df2_cf = pd.read_pickle(user_folder + 'df2_cf.pkl')\n",
    "\n",
    "    Nruns = 2\n",
    "    trials_per_run = {}\n",
    "\n",
    "    for run_no in range(1,Nruns+1):\n",
    "\n",
    "        # extract run data\n",
    "        df2_cf_R = df2_cf[df2_cf['Run']==run_no]\n",
    "\n",
    "        # compute Ntrials\n",
    "        Ntrials = len(df2_cf_R)\n",
    "\n",
    "        # Compute block size\n",
    "        if Ntrials%Nblocks_per_run != 0:\n",
    "            print('PROBLEM: Nblocks_per_run has to divide Ntrials')\n",
    "        else:\n",
    "            block_size = int(len(df2_cf_R)/Nblocks_per_run)\n",
    "\n",
    "        # Split trials in groups\n",
    "        trials = df2_cf_R['Trial'].tolist()\n",
    "        trials_per_run[str(run_no)] = [trials[i:i + block_size] for i in range(0, len(trials), block_size)]\n",
    "\n",
    "    # Make list of trials (concatenate blocks)\n",
    "    lst_trials = []\n",
    "    for trials_per_R in trials_per_run.values():\n",
    "        for trials in trials_per_R:\n",
    "            lst_trials.append(trials)\n",
    "\n",
    "    # Compute fb_by_cue per block\n",
    "    df2_count_Rindiv = {}\n",
    "    for i, trials in enumerate(lst_trials):\n",
    "        df2_count_Bindiv[i] = count_fb_by_cue(df2_cf[df2_cf['Trial'].isin(trials)]).fillna(0)\n",
    "        df2_count_Bindiv[i].insert(0, 'Block', i+1)\n",
    "        df2_count_Bindiv[i].insert(0, 'ID', ID)\n",
    "\n",
    "    # Concat\n",
    "    tmp = pd.concat([df for df in df2_count_Bindiv.values()])\n",
    "    all_counts_B = pd.concat([all_counts_B, tmp])\n",
    "    \n",
    "all_counts_B.rename(columns={\"index\": \"Cue\"}, inplace=True)\n",
    "all_counts_B.reset_index(inplace=True)\n",
    "all_counts_B.drop('index', axis=1, inplace=True)\n",
    "\n",
    "# Concatenante hit and miss to have reward columns\n",
    "for rew in ['-5', '-1', '1', '5']:\n",
    "    all_counts_B['R_' + rew] = all_counts_B['FB_' + rew] + all_counts_B['FB_no_' + rew]\n",
    "    \n",
    "# Save all_counts_B as pickle\n",
    "all_counts_B.to_pickle(all_users_folder + 'all_counts_B.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea496004-a8f3-4917-b05d-c5edadf3cf70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
