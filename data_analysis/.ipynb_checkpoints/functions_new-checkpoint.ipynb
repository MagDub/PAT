{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a61108ed-fb3a-4c22-b0d5-c7046ffa1c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import pearsonr, bernoulli\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "import ptitprince as pt # rainplot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1521503-0078-4f97-8797-934f1f052c4f",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "25470086-7631-4ff6-9d93-01d68ce4af64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fig_modelpred_on_behav(ev_per_trial, p_hit_per_trial, all_users_folder):\n",
    "\n",
    "    # Timepoints\n",
    "    window_size = 16\n",
    "    N_trials = 112\n",
    "    timepoints = ['t'+ str(t+1) for t in range(int(N_trials/window_size))]\n",
    "\n",
    "    # Load behaviour and compute stats\n",
    "    hit_perc_per_t = pd.read_pickle(all_users_folder + 'hit_perc_per_t/hit_perc_per_t_w' + str(window_size) + '.pkl');\n",
    "    hit_perc_per_t.drop('ID', axis=1, inplace=True);\n",
    "    stats_hits_perc_per_t = hit_perc_per_t.groupby('Code').agg(['mean', 'var']).T.swaplevel(axis=0);\n",
    "\n",
    "    # Load model predictions and compute stats\n",
    "    ev_per_trial.drop('ID', axis=1, inplace=True);\n",
    "    stats_ev_per_trial = ev_per_trial.groupby('Cue').agg(['mean', 'var']).T.swaplevel(axis=0)\n",
    "    stats_ev_per_trial.columns = 'Cue_'+stats_ev_per_trial.columns\n",
    "\n",
    "    p_hit_per_trial.drop('ID', axis=1, inplace=True);\n",
    "    stats_p_hit_per_trial = p_hit_per_trial.groupby('Cue').agg(['mean', 'var']).T.swaplevel(axis=0)\n",
    "    stats_p_hit_per_trial.columns = 'Cue_'+stats_p_hit_per_trial.columns\n",
    "\n",
    "    # Plot\n",
    "    f, axs = plt.subplots(2, 1, figsize=(10, 6), dpi=80)\n",
    "    plt.subplots_adjust(hspace = 0.4)\n",
    "\n",
    "    x_mod = np.arange(len(stats_ev_per_trial.loc['mean']))+1\n",
    "    x_behav = np.arange(len(timepoints))*4+4\n",
    "\n",
    "    for cue, color, alpha in zip(['Cue_HP', 'Cue_LP', 'Cue_LR', 'Cue_HR'], ['red', 'red', 'green', 'green'], [0.6, 0.3, 0.3, 0.6]):\n",
    "        # Hit probabilites\n",
    "        m=axs[0].plot(x_mod, stats_p_hit_per_trial.loc['mean'][cue], '.-', color=color, alpha=alpha);\n",
    "        # Behaviour: sliding average\n",
    "        b=axs[0].plot(x_behav, stats_hits_perc_per_t.loc['mean'][cue], '.-', color='gray', alpha=alpha);\n",
    "        # Expected values\n",
    "        m=axs[1].plot(x_mod, stats_ev_per_trial.loc['mean'][cue], '.-', color=color, alpha=alpha);\n",
    "\n",
    "    for ax in axs:\n",
    "        ax.grid(axis='x', color='0.95');\n",
    "        ax.set_xticks(x_mod);\n",
    "    \n",
    "    axs[0].set_title('Model probability of hit', fontsize=16);\n",
    "    axs[1].set_title('Model expected values', fontsize=16);\n",
    "    \n",
    "    axs[0].set_ylabel(\"Hit [%]\", fontsize=16);\n",
    "    axs[1].set_ylabel(\"Values\", fontsize=16);\n",
    "    \n",
    "    axs[0].set_ylim([0,1]);\n",
    "    axs[1].set_ylim([-3,3]);\n",
    "    \n",
    "    axs[0].legend(b, {'Behaviour'})\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2ebec1bb-c224-4a23-93b3-d2c188f2e43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_parameters(data_mod, param_names):\n",
    "    \n",
    "    Nparam = len(param_names)\n",
    "    \n",
    "    if Nparam<=3:\n",
    "        f, axs = plt.subplots(1, Nparam, figsize=(Nparam*6, 5))\n",
    "    elif Nparam==4:\n",
    "        f, axs = plt.subplots(2, 2, figsize=(2*6, 2*5))\n",
    "        axs = axs.reshape(-1)\n",
    "    else:\n",
    "        f, axs = plt.subplots(2, 3, figsize=(3*6, 2*5))\n",
    "        axs = axs.reshape(-1)\n",
    "        \n",
    "    plt.subplots_adjust(hspace = 0.3)\n",
    "        \n",
    "    pal = sns.color_palette(n_colors=1)\n",
    "    \n",
    "    if Nparam == 1:\n",
    "        ax, param = axs, param_names[0]\n",
    "        y = data_mod[param].squeeze().tolist()\n",
    "        pt.half_violinplot(ax=ax, x = y, palette = pal, bw = .2, cut = 0., scale = \"area\", width = .6, inner = None, orient = 'h')\n",
    "        sns.stripplot(ax=ax, x = y, palette = pal, edgecolor = \"white\", size = 5, jitter = 1, zorder = 0, orient = 'h', alpha=.35)\n",
    "        sns.boxplot(x = y, saturation=1, showfliers=False, width=0.15, boxprops={'zorder': 3, 'facecolor': 'none'}, ax=ax)\n",
    "        ax.set_title('Parameter: ' + param, fontsize=18)\n",
    "        ax.set_xlabel('Best fit parameter value', fontsize=16)\n",
    "\n",
    "    else:\n",
    "        for ax, param in zip(axs, param_names):\n",
    "            y = data_mod[param].tolist()\n",
    "            # plot clouds\n",
    "            pt.half_violinplot(ax=ax, x = y, palette = pal, bw = .2, cut = 0., scale = \"area\", width = .6, inner = None, orient = 'h')\n",
    "            # add rain\n",
    "            sns.stripplot(ax=ax, x = y, palette = pal, edgecolor = \"white\", size = 5, jitter = 1, zorder = 0, orient = 'h', alpha=.35)\n",
    "            sns.boxplot(x = y, saturation=1, showfliers=False, width=0.15, boxprops={'zorder': 3, 'facecolor': 'none'}, ax=ax)\n",
    "            # Makeup\n",
    "            ax.set_title('Parameter: ' + param, fontsize=18)\n",
    "            ax.set_xlabel('Best fit parameter value', fontsize=16)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd22618d-6a43-4053-addc-f66bd19ae031",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_correlation(title, x, y, data, ax, text_pos, xlabel, ylabel, xlim, ylim):\n",
    "        \n",
    "    # Initialise figue\n",
    "    ax.set_title(title, fontsize = 22)\n",
    "\n",
    "    # Scatter plot\n",
    "    sns.scatterplot( x = x, y = y, data = data, ax = ax);\n",
    "\n",
    "    # Linear regression line\n",
    "    sns.regplot(x = x, y = y, data = data, ax = ax);\n",
    "    \n",
    "    # Plot horizontal line\n",
    "    ax.axhline(y=0, color='k', linestyle=':')\n",
    "\n",
    "    # Compute correlation stats (r and p values)\n",
    "    r, p = pearsonr(data[x], data[y])\n",
    "    \n",
    "    # Write stats on fig\n",
    "    if p<0.01:\n",
    "        ax.text(text_pos[0], text_pos[1], 'r={:.2f} \\np<0.01'.format(r, p), transform=ax.transAxes, fontsize=16)\n",
    "    else:    \n",
    "        ax.text(text_pos[0], text_pos[1], 'r={:.2f} \\np={:.2g}'.format(r, p), transform=ax.transAxes, fontsize=16)\n",
    "    \n",
    "    # Properties\n",
    "    ax.set_ylabel(ylabel, fontsize=15)\n",
    "    ax.set_ylim(bottom=ylim[0], top=ylim[1])\n",
    "    \n",
    "    ax.set_xlabel(xlabel, fontsize=15)\n",
    "    ax.set_xlim(left=xlim[0], right=xlim[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "752cfc61-37ae-45e9-ba77-dc29f33b1ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_param_recov_correlations(df):\n",
    "    \n",
    "    # get Param names\n",
    "    param_names = df.columns[2::].tolist()\n",
    "\n",
    "    Nparam = len(param_names)\n",
    "\n",
    "    if Nparam<=3:\n",
    "        #f, axs = plt.subplots(1, Nparam, figsize=(Nparam*6, 5))\n",
    "        f, axs = plt.subplots(1, Nparam, figsize=(Nparam*4, 3))\n",
    "    elif Nparam==4:\n",
    "        f, axs = plt.subplots(2, 2, figsize=(2*6, 2*5))\n",
    "        axs = axs.reshape(-1)\n",
    "    else:\n",
    "        f, axs = plt.subplots(2, 3, figsize=(3*6, 2*5))\n",
    "        axs = axs.reshape(-1)\n",
    "\n",
    "    plt.subplots_adjust(hspace = 0.3)\n",
    "\n",
    "    for i, param in enumerate(param_names):\n",
    "\n",
    "        lims = [math.floor(df[param].min()), math.ceil(df[param].max())]\n",
    "\n",
    "        df_tmp = df.pivot(index = 'simID', columns = 'Type', values=param)\n",
    "        \n",
    "        ax = axs if Nparam==1 else axs[i]\n",
    "\n",
    "        plot_correlation(title=param, x='Fit', y='Sim',\n",
    "                         data=df_tmp, ax=ax, text_pos=[.2,.8], \n",
    "                         xlabel='Fitted', ylabel='Simulated', xlim=lims, ylim=lims)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3cc4a79a-7ffe-422e-b508-9e0ba6a66029",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_param_recov_conf_matrix(df):\n",
    "    \n",
    "    #f, axs = plt.subplots(1, 1, figsize=(7, 6))\n",
    "    f, axs = plt.subplots(1, 1, figsize=(4, 3))\n",
    "\n",
    "    # get Param names\n",
    "    param_names = df.columns[2::].tolist()\n",
    "\n",
    "    # Initialise matrices of nans\n",
    "    Nparam = len(param_names)\n",
    "    confusion_mat = np.empty((Nparam, Nparam))\n",
    "    confusion_mat[:] = np.NaN\n",
    "\n",
    "    # Store pearson correlations\n",
    "    for i_sim, param_sim_name in enumerate(param_names):\n",
    "        for i_fit, param_fit_name in enumerate(param_names):\n",
    "            param_sim_values = df[df['Type']=='Sim'][param_sim_name]\n",
    "            param_fit_values = df[df['Type']=='Fit'][param_fit_name]\n",
    "            corr, _ = pearsonr(param_sim_values, param_fit_values)\n",
    "            confusion_mat[i_sim, i_fit] = corr\n",
    "            #print('sim: ' + param_sim_name + ' fit: ' + param_fit_name)\n",
    "            #print(corr)\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    ax = sns.heatmap(confusion_mat.T, vmin=-1, vmax=1, annot=True, annot_kws={\"fontsize\":12, \"weight\":\"normal\"}, cmap='coolwarm')\n",
    "    ax.set_xticklabels(param_names, fontsize = 12)\n",
    "    ax.set_yticklabels(param_names, fontsize = 12)\n",
    "    ax.set_xlabel('Simulated', fontsize = 14)\n",
    "    ax.set_ylabel('Fitted', fontsize = 14)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a346f1ad-120b-44b8-b3ef-cef824c7f423",
   "metadata": {},
   "source": [
    "## Model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8fca603-74c6-46b0-b3c4-58df9d552d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    \n",
    "    def __init__(self, mod_name, value_fct, dec_fct, param_names):\n",
    "        self.mod_name = mod_name\n",
    "        self.value_fct = value_fct\n",
    "        self.dec_fct = dec_fct\n",
    "        self.param_names = param_names\n",
    "        self.param_values = []\n",
    "        self.fbs_all_cues = []\n",
    "        self.p_hit_all_cues = []\n",
    "        self.vt_all_cues = []\n",
    "        self.pe_all_cues = []\n",
    "        self.trialNo_all_cues = []\n",
    "        self.isHit_all_cues = []\n",
    "        self.Ntrials_per_cue = []\n",
    "        self.nLLs_all_cues = []\n",
    "        self.total_nLL_per_cue = []\n",
    "        self.nLL = []\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f'Model(\"{self.mod_name}\",\"{self.param_names}\")'\n",
    "    \n",
    "    def set_part_data(self, ID, fbs_all_cues, isHit_all_cues, trialNo_all_cues):\n",
    "        self.ID = ID\n",
    "        self.fbs_all_cues = fbs_all_cues\n",
    "        self.isHit_all_cues = isHit_all_cues\n",
    "        self.trialNo_all_cues = trialNo_all_cues\n",
    "        self.p_hit_all_cues = self.get_empty_dict(fbs_all_cues)\n",
    "        self.vt_all_cues = self.get_empty_dict(fbs_all_cues)\n",
    "        self.pe_all_cues = self.get_empty_dict(fbs_all_cues)\n",
    "        self.nLLs_all_cues = self.get_empty_dict(fbs_all_cues)\n",
    "        self.total_nLL_per_cue = dict.fromkeys(fbs_all_cues.keys())\n",
    "    \n",
    "    def set_dataset(self, fbs_all_cues, trialNo_all_cues):\n",
    "        self.fbs_all_cues = fbs_all_cues\n",
    "        self.trialNo_all_cues = trialNo_all_cues\n",
    "        self.p_hit_all_cues = self.get_empty_dict(fbs_all_cues)\n",
    "        self.vt_all_cues = self.get_empty_dict(fbs_all_cues)\n",
    "        self.pe_all_cues = self.get_empty_dict(fbs_all_cues)\n",
    "        self.isHit_all_cues = self.get_empty_dict(fbs_all_cues)\n",
    "        self.nLLs_all_cues = self.get_empty_dict(fbs_all_cues)\n",
    "        self.total_nLL_per_cue = dict.fromkeys(fbs_all_cues.keys())\n",
    "        \n",
    "    def set_param_values(self, param_values):\n",
    "        self.param_values = param_values\n",
    "        \n",
    "    def get_empty_dict(self, fbs_all_cues):\n",
    "        tmp = dict.fromkeys(fbs_all_cues.keys())\n",
    "        _, rand_fb = random.choice(list(fbs_all_cues.items()))\n",
    "        self.Ntrials_per_cue = len(rand_fb)\n",
    "        for cue in tmp.keys():\n",
    "            tmp[cue] = np.empty(len(rand_fb), dtype=object)\n",
    "        return tmp\n",
    "\n",
    "    def compute_nLL_per_cue(self, p_hit_all_cues, hits_all_cues):\n",
    "        \n",
    "        for cue, p_hit in p_hit_all_cues.items():\n",
    "            \n",
    "            for ind, f_x in enumerate(p_hit):\n",
    "                \n",
    "                y = hits_all_cues[cue][ind]\n",
    "                \n",
    "                # logistic reg cost function\n",
    "                self.nLLs_all_cues[cue][ind] = - y * np.log(f_x) - (1-y) * np.log(1-f_x)\n",
    "            \n",
    "            self.total_nLL_per_cue[cue] = sum(self.nLLs_all_cues[cue])\n",
    "        \n",
    "    \n",
    "    def total_nLL(self, param_values):\n",
    "        \n",
    "        # set parameter values\n",
    "        self.set_param_values(param_values)\n",
    "        \n",
    "        # run model\n",
    "        self.run_model(sim_behav=0)\n",
    "        \n",
    "        # compute nLL per cue TODO change the sim_hits\n",
    "        self.compute_nLL_per_cue(self.p_hit_all_cues, self.isHit_all_cues)\n",
    "        \n",
    "        # total\n",
    "        total_nLL = sum(self.total_nLL_per_cue.values())\n",
    "        \n",
    "        return total_nLL\n",
    "    \n",
    "    \n",
    "    def fit(self, param_lower_bounds, param_upper_bounds, n_iterations, method='TNC'):\n",
    "        \n",
    "        # compute sequence of parameter bounds\n",
    "        bounds = [[low,up] for low, up in zip(param_lower_bounds, param_upper_bounds)]\n",
    "                \n",
    "        # init\n",
    "        mat_min_nLL=[]\n",
    "        mat_best_params=[]\n",
    "        \n",
    "        for i in range(0, n_iterations):\n",
    "            \n",
    "            # define the starting point as a random sample from the domain\n",
    "            initial_guess = [np.random.uniform(bound[0],bound[1],1) for bound in bounds]\n",
    "            \n",
    "            # find the min likelihood \n",
    "            result = minimize(self.total_nLL, initial_guess, method = method, bounds = bounds, \n",
    "                              options={'xtol': 1e-8, 'disp': False})\n",
    "\n",
    "            # store min_nLL and parameters\n",
    "            mat_min_nLL.append(result.fun)\n",
    "            mat_best_params.append(result.x)\n",
    "\n",
    "        # Find best params\n",
    "        ind = np.argmin(mat_min_nLL)\n",
    "        best_params = mat_best_params[ind]\n",
    "\n",
    "        # Compute best LL \n",
    "        nLL = self.total_nLL(best_params)\n",
    "        \n",
    "        # Store\n",
    "        self.nLL = nLL\n",
    "        \n",
    "        return best_params, nLL\n",
    "            \n",
    "                    \n",
    "    def run_model(self, sim_behav):\n",
    "        \n",
    "        # set v0 to 0 or get its value if its a free parameter\n",
    "        v0 = 0 if 'v0' not in self.param_names else self.param_values[self.param_names.index('v0')]\n",
    "        \n",
    "        for cue in self.fbs_all_cues.keys():\n",
    "            \n",
    "            # t = 0\n",
    "            self.vt_all_cues[cue][0] = v0\n",
    "\n",
    "            for t, trial in zip(range(0, self.Ntrials_per_cue), self.trialNo_all_cues[cue]):\n",
    "                \n",
    "                # make a decision\n",
    "                self.p_hit_all_cues[cue][t] = self.dec_fct(self.vt_all_cues[cue][t], trial, self.param_names, self.param_values)\n",
    "                \n",
    "                if sim_behav == 1:\n",
    "                    #self.sim_hits_all_cues[cue][t] = 1 if self.p_hit_all_cues[cue][t] >= 0.5 else 0\n",
    "                    self.isHit_all_cues[cue][t] = float(bernoulli.rvs(self.p_hit_all_cues[cue][t], size=1))\n",
    "                    \n",
    "                # compute PE and new v\n",
    "                vt, pe = self.value_fct(vt = self.vt_all_cues[cue][t], isHit = self.isHit_all_cues[cue][t], fb = self.fbs_all_cues[cue][t], \n",
    "                                        param_names = self.param_names, param_values = self.param_values)\n",
    "                self.pe_all_cues[cue][t] = pe\n",
    "\n",
    "                # update v\n",
    "                if t < (self.Ntrials_per_cue-1):\n",
    "                    self.vt_all_cues[cue][t+1] = vt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e726d341-3deb-4377-a71c-bd9a6a5c0a7d",
   "metadata": {},
   "source": [
    "## Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "048715f2-0fc1-436c-8f9c-9026370ff06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model_to_data(uniqueIDs, mod_info, param_lower_bounds, param_upper_bounds, all_users_folder):\n",
    "    \n",
    "    # Fit\n",
    "    all_users = {}\n",
    "    p_hit_per_trial = pd.DataFrame([])\n",
    "    ev_per_trial = pd.DataFrame([])\n",
    "    pe_per_trial = pd.DataFrame([])\n",
    "    isHit_per_trial = pd.DataFrame([])\n",
    "    fbs_per_trial = pd.DataFrame([])\n",
    "    trialNo_per_trial = pd.DataFrame([])\n",
    "\n",
    "    for n_part,ID in enumerate(uniqueIDs): \n",
    "\n",
    "        # Get data\n",
    "        user_folder = 'data/user_' + ID + '/'\n",
    "        df2_cf = pd.read_pickle(user_folder + 'df2_cf.pkl')\n",
    "        isHit_all_cues, fbs_all_cues, trialNo_all_cues = extract_hits_fbs(df2_cf)\n",
    "\n",
    "        # Create a new Model object\n",
    "        mod = Model(mod_name = mod_info['name'],\n",
    "                    value_fct = mod_info['value_fct'], \n",
    "                    dec_fct = mod_info['dec_fct'], \n",
    "                    param_names = mod_info['param_names'])\n",
    "\n",
    "        # Input data to model\n",
    "        mod.set_part_data(ID, fbs_all_cues, isHit_all_cues, trialNo_all_cues)\n",
    "\n",
    "        # Fit model\n",
    "        mod.fit(param_lower_bounds, param_upper_bounds, n_iterations=5)\n",
    "\n",
    "        # Nested dictionnary user data\n",
    "        all_users[n_part] = {}\n",
    "        all_users[n_part]['ID'] = mod.ID\n",
    "        all_users[n_part]['nLL'] = mod.nLL\n",
    "        all_users[n_part]['Nparams'] = len(mod.param_names)\n",
    "\n",
    "        for i in range(0,len(mod.param_names)):\n",
    "            all_users[n_part][mod.param_names[i]] = mod.param_values[i]\n",
    "\n",
    "        # Concatenated model predictions: phit\n",
    "        tmp = pd.DataFrame(mod.p_hit_all_cues).transpose()\n",
    "        tmp.columns = tmp.columns + 1\n",
    "        tmp = tmp.reset_index().rename(columns = {'index': 'Cue'})\n",
    "        tmp.insert(0,'ID',ID)\n",
    "        p_hit_per_trial = pd.concat([tmp, p_hit_per_trial], axis=0)\n",
    "\n",
    "        # Concatenated model predictions: EVs\n",
    "        tmp = pd.DataFrame(mod.vt_all_cues).transpose()\n",
    "        tmp.columns = tmp.columns+1\n",
    "        tmp = tmp.reset_index().rename(columns = {'index': 'Cue'})\n",
    "        tmp.insert(0,'ID',ID)\n",
    "        ev_per_trial = pd.concat([tmp, ev_per_trial], axis = 0)\n",
    "        \n",
    "        # Concatenated prediction errors: PEs\n",
    "        tmp = pd.DataFrame(mod.pe_all_cues).transpose()\n",
    "        tmp.columns = tmp.columns+1\n",
    "        tmp = tmp.reset_index().rename(columns = {'index': 'Cue'})\n",
    "        tmp.insert(0,'ID',ID)\n",
    "        pe_per_trial = pd.concat([tmp, pe_per_trial], axis = 0)\n",
    "        \n",
    "        # Concatenated hits: isHit\n",
    "        tmp = pd.DataFrame(mod.isHit_all_cues).transpose()\n",
    "        tmp.columns = tmp.columns+1\n",
    "        tmp = tmp.reset_index().rename(columns = {'index': 'Cue'})\n",
    "        tmp.insert(0,'ID',ID)\n",
    "        isHit_per_trial = pd.concat([tmp, isHit_per_trial], axis = 0)\n",
    "        \n",
    "        # Concatenated feedbacks: fbs\n",
    "        tmp = pd.DataFrame(mod.fbs_all_cues).transpose()\n",
    "        tmp.columns = tmp.columns+1\n",
    "        tmp = tmp.reset_index().rename(columns = {'index': 'Cue'})\n",
    "        tmp.insert(0,'ID',ID)\n",
    "        fbs_per_trial = pd.concat([tmp, fbs_per_trial], axis = 0)\n",
    "                \n",
    "        # Concatenated trials Nb: trialNo_all_cues\n",
    "        tmp = pd.DataFrame(mod.trialNo_all_cues).transpose()\n",
    "        tmp.columns = tmp.columns+1\n",
    "        tmp = tmp.reset_index().rename(columns = {'index': 'Cue'})\n",
    "        tmp.insert(0,'ID',ID)\n",
    "        trialNo_per_trial = pd.concat([tmp, trialNo_per_trial], axis = 0)\n",
    "        \n",
    "        \n",
    "    # Save mod LLs and parameter values\n",
    "    mod_fit = pd.DataFrame(all_users).transpose()\n",
    "    mod_fit.to_pickle(all_users_folder + 'mod_param_fits.pkl')\n",
    "\n",
    "    # Save mod predictions\n",
    "    p_hit_per_trial = p_hit_per_trial.sort_values(by ='ID').reset_index(drop = True)\n",
    "    p_hit_per_trial.to_pickle(all_users_folder + 'mod_p_hit_per_trial.pkl')\n",
    "    \n",
    "    ev_per_trial = ev_per_trial.sort_values(by ='ID').reset_index(drop = True)\n",
    "    ev_per_trial.to_pickle(all_users_folder + 'mod_ev_per_trial.pkl')\n",
    "    \n",
    "    pe_per_trial = pe_per_trial.sort_values(by ='ID').reset_index(drop = True)\n",
    "    pe_per_trial.to_pickle(all_users_folder + 'mod_pe_per_trial.pkl')\n",
    "    \n",
    "    isHit_per_trial = isHit_per_trial.sort_values(by ='ID').reset_index(drop = True)\n",
    "    isHit_per_trial.to_pickle(all_users_folder + 'mod_isHit_per_trial.pkl')\n",
    "    \n",
    "    trialNo_per_trial = trialNo_per_trial.sort_values(by ='ID').reset_index(drop = True)\n",
    "    trialNo_per_trial.to_pickle(all_users_folder + 'mod_trialNo_per_trial.pkl')\n",
    "    \n",
    "    fbs_per_trial = fbs_per_trial.sort_values(by ='ID').reset_index(drop = True)\n",
    "    fbs_per_trial.to_pickle(all_users_folder + 'mod_fbs_per_trial.pkl')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d01cef4c-9bd6-41b1-b964-f1d620aae7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat_param_lists(all_sim_param_values, all_fit_param_values, mod_info):\n",
    "    \n",
    "    df_sim = pd.DataFrame(all_sim_param_values, columns = mod_info['param_names'])\n",
    "    df_sim.insert(0, 'Type', 'Sim')\n",
    "    df_sim = df_sim.rename_axis('simID').reset_index()\n",
    "\n",
    "    df_fit = pd.DataFrame(all_fit_param_values, columns = mod_info['param_names'])\n",
    "    df_fit.insert(0, 'Type', 'Fit')\n",
    "    df_fit = df_fit.rename_axis('simID').reset_index()\n",
    "    \n",
    "    df = pd.concat([df_sim, df_fit])\n",
    "    df.sort_values(by='simID', ascending=True, inplace = True)\n",
    "    df.reset_index(inplace = True, drop = True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00149e8e-e89f-43c7-bc3a-24d6243ba097",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hits_fbs(df):\n",
    "    \n",
    "    isHit_all_cues = {}\n",
    "    fbs_all_cues = {}\n",
    "    trialNo_all_cues = {}\n",
    "        \n",
    "    for cue in ['HR', 'LR', 'HP', 'LP']:\n",
    "\n",
    "        # Extract cue data\n",
    "        cue_data_tmp = df[df['Code']==('Cue_' + cue)] \n",
    "\n",
    "        # Create a cue trial column\n",
    "        cue_data_tmp.insert(0, \"CueTrial\", list(range(1,len(cue_data_tmp)+1)))\n",
    "\n",
    "        # Store all in dictionnaries\n",
    "        isHit_all_cues[cue]=cue_data_tmp['isHit'].tolist()\n",
    "        fbs_all_cues[cue]=cue_data_tmp['FBs'].tolist()\n",
    "        trialNo_all_cues[cue]=cue_data_tmp['Trial'].tolist()\n",
    "        \n",
    "    return isHit_all_cues, fbs_all_cues, trialNo_all_cues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bacec63-9ad3-430d-9a1f-314d77dcc7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_rand_dataset():\n",
    "    \n",
    "    all_users_folder = 'data/all_users/'\n",
    "\n",
    "    # Load IDs\n",
    "    with open('uniqueIDs.pkl', 'rb') as f:\n",
    "        uniqueIDs = pickle.load(f)\n",
    "\n",
    "    # Extract random data set\n",
    "    random.shuffle(uniqueIDs)\n",
    "    ID = uniqueIDs[0]\n",
    "    user_folder = 'data/user_' + ID + '/'\n",
    "    df2_cf = pd.read_pickle(user_folder + 'df2_cf.pkl')\n",
    "    _, fbs_all_cues, trialNo_all_cues = extract_hits_fbs(df2_cf)\n",
    "    #print('Dataset from ID =',ID)\n",
    "    \n",
    "    return fbs_all_cues, trialNo_all_cues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d60d4b5e-2234-4479-8887-18fbf59e7478",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_fit_model(mod_info, param_lower_bounds, param_upper_bounds, Nsim, all_users_folder):\n",
    "\n",
    "    # Create a new Model object\n",
    "    mod = Model(mod_name = mod_info['name'], \n",
    "                value_fct = mod_info['value_fct'], \n",
    "                dec_fct = mod_info['dec_fct'], \n",
    "                param_names = mod_info['param_names'])\n",
    "    \n",
    "    # print model info\n",
    "    print(repr(mod))\n",
    "\n",
    "    # init\n",
    "    all_sim_param_values = []\n",
    "    all_fit_param_values = []\n",
    "    \n",
    "    # bounds\n",
    "    bounds = [[low,up] for low, up in zip(param_lower_bounds, param_upper_bounds)]\n",
    "\n",
    "    for sim_id in range(0, Nsim):\n",
    "\n",
    "        if sim_id>4 and sim_id%int(round(Nsim/4))==0:\n",
    "            print(sim_id)\n",
    "\n",
    "        # extract random dataset and set\n",
    "        fbs_all_cues, trialNo_all_cues = extract_rand_dataset()\n",
    "        mod.set_dataset(fbs_all_cues, trialNo_all_cues)\n",
    "\n",
    "        # random param values for simulation\n",
    "        generating_param_values = [np.random.uniform(bound[0],bound[1],1) for bound in bounds]\n",
    "\n",
    "        # set param values\n",
    "        mod.set_param_values(generating_param_values)\n",
    "\n",
    "        # simulate behav\n",
    "        mod.run_model(sim_behav=1)\n",
    "\n",
    "        # fit\n",
    "        best_params, _ = mod.fit(param_lower_bounds, param_upper_bounds, n_iterations = 10)\n",
    "\n",
    "        # store\n",
    "        all_sim_param_values.append(np.concatenate(generating_param_values, axis=0))\n",
    "        all_fit_param_values.append(best_params)\n",
    "\n",
    "    # Reformat\n",
    "    df = reformat_param_lists(all_sim_param_values, all_fit_param_values, mod_info)\n",
    "\n",
    "    # Save\n",
    "    filename = all_users_folder + 'sim_refit/' + mod_info['name'] + '.pkl'\n",
    "    df.to_pickle(filename)\n",
    "    print('DONE. Saved to: ', filename.strip())\n",
    "    \n",
    "    return mod"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa9e6c1-9e06-4668-aa56-7719a4163372",
   "metadata": {},
   "source": [
    "## Value function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "25d19586-61b6-45fe-ab0e-ba6f4f729374",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescorla_wagner_2LR_1t(vt, isHit, fb, param_names, param_values):   \n",
    "    \n",
    "    # set alpha to 1 or get its value if its a free parameter\n",
    "    alpha_rew = param_values[param_names.index('alpha_rew')]\n",
    "    alpha_pun = param_values[param_names.index('alpha_pun')]\n",
    "    \n",
    "    pe = fb - vt\n",
    "\n",
    "    if isHit == 1:\n",
    "        if fb > 0:\n",
    "            vt = vt + alpha_rew * pe\n",
    "        elif fb < 0:\n",
    "            vt = vt + alpha_pun * pe \n",
    "    \n",
    "    elif isHit == 0:\n",
    "        pe = np.nan\n",
    "        \n",
    "    return vt, pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cf4247ec-e13f-41c1-9a7f-b6d085e50080",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescorla_wagner_1t(vt, isHit, fb, param_names, param_values):   \n",
    "    \n",
    "    # set alpha to 1 or get its value if its a free parameter\n",
    "    alpha = 0.1 if 'alpha' not in param_names else param_values[param_names.index('alpha')]\n",
    "    \n",
    "    if isHit == 1:\n",
    "        pe = fb - vt\n",
    "        vt = vt + alpha * pe \n",
    "    \n",
    "    elif isHit == 0:\n",
    "        pe = np.nan\n",
    "        \n",
    "    return vt, pe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4d09ee-3409-412e-aec9-f6383fb791d1",
   "metadata": {},
   "source": [
    "## Decision function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6e708fe5-1473-4238-b15b-3abbd635df83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_softmax_1t(vt, trial, param_names, param_values): \n",
    "    \n",
    "    # set beta to 1 or get its value if its a free parameter\n",
    "    # same for press bias pi to 0, and for shrinking press bias pi_t\n",
    "    beta = 1 if 'beta' not in param_names else param_values[param_names.index('beta')]\n",
    "    pi = 0 if 'pi' not in param_names else param_values[param_names.index('pi')]\n",
    "    pi_t = 0 if 'pi_t' not in param_names else param_values[param_names.index('pi_t')]\n",
    "    \n",
    "    # normalise the trial, start at 1 at the new block\n",
    "    norm_trial = (trial-56) if trial>56 else trial\n",
    "    shrink = (56 - norm_trial)/56\n",
    "        \n",
    "    v_no_hit = 0\n",
    "    v_hit = vt + pi + pi_t*shrink\n",
    "    diff = v_no_hit - v_hit\n",
    "    \n",
    "    p_hit = 1 / (1 + np.exp(beta * diff))\n",
    "            \n",
    "    return p_hit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f0366188-6827-4e52-9b5e-a3bc6f0ebecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_softmax_1t_2pit(vt, trial, param_names, param_values): \n",
    "    \n",
    "    # set beta to 1 or get its value if its a free parameter\n",
    "    # same for press bias pi to 0, and for shrinking press bias pi_t\n",
    "    beta = 1 if 'beta' not in param_names else param_values[param_names.index('beta')]\n",
    "    \n",
    "    pi_t_1 = 0 if 'pi_t_1' not in param_names else param_values[param_names.index('pi_t_1')]\n",
    "    pi_t_2 = 0 if 'pi_t_2' not in param_names else param_values[param_names.index('pi_t_2')]\n",
    "    \n",
    "    # normalise the trial, start at 1 at the new block\n",
    "    if trial>56:\n",
    "        norm_trial = (trial-56) \n",
    "        pi_t = pi_t_2\n",
    "    else:\n",
    "        norm_trial = trial\n",
    "        pi_t = pi_t_1\n",
    "    \n",
    "    shrink = (56 - norm_trial)/56\n",
    "        \n",
    "    v_no_hit = 0\n",
    "    v_hit = vt + pi_t*shrink\n",
    "    diff = v_no_hit - v_hit\n",
    "    \n",
    "    p_hit = 1 / (1 + np.exp(beta * diff))\n",
    "            \n",
    "    return p_hit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e700c3-c1d4-43fe-a72f-72f0a1eee8aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
