{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "243982d9-7c77-43d7-a746-b2b976fabc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On terminal: conda activate python38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bb5ab949-f34a-4ad2-97dc-8dad2820f9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5833e36f-e7d9-461a-ac5c-9502facd812e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c34670d5-8253-429a-b580-5c27c4aa29c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Il doit y a voir petite valeur dans le log !! (pas defini)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1b2eda",
   "metadata": {},
   "source": [
    "# Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0d17c5dc-31df-428b-8339-d1fd45d548f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hits_fbs(df):\n",
    "    \n",
    "    isHit_all_cues = {}\n",
    "    fbs_all_cues = {}\n",
    "        \n",
    "    for cue in ['HR', 'LR', 'HP', 'LP']:\n",
    "\n",
    "        # Extract cue data\n",
    "        cue_data_tmp = df[df['Code']==('Cue_' + cue)] \n",
    "\n",
    "        # Create a cue trial column\n",
    "        cue_data_tmp.insert(0, \"CueTrial\", list(range(1,len(cue_data_tmp)+1)))\n",
    "\n",
    "        # Store all in dictionnaries\n",
    "        isHit_all_cues[cue]=cue_data_tmp['isHit'].tolist()\n",
    "        fbs_all_cues[cue]=cue_data_tmp['FBs'].tolist()\n",
    "        \n",
    "    return isHit_all_cues, fbs_all_cues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fb6b89c6-ac50-428f-9378-a2d15e41034f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ID = '007'\n",
    "\n",
    "# Get data\n",
    "user_folder = 'data/user_' + ID + '/'\n",
    "df2_cf = pd.read_pickle(user_folder + 'df2_cf.pkl')\n",
    "\n",
    "# Exctract hits and fbs per cue\n",
    "isHit_all_cues, fbs_all_cues = extract_hits_fbs(df2_cf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc45f463-b67b-4425-b665-f05209606213",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Functions and classes for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2ae4de85-402d-496a-bfb5-a9a782a33ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescorla_wagner(fbs_all_cues, param_values, param_names):\n",
    "    \n",
    "    # Free parameters\n",
    "    v0 = param_values[param_names.index('v0')]\n",
    "    alpha = param_values[param_names.index('alpha')]\n",
    "    \n",
    "    # Initialise empty dicitonnary\n",
    "    vt_all_cues = dict.fromkeys(fbs_all_cues.keys())\n",
    "    \n",
    "    # Iterate over cues\n",
    "    for cue, fbs in fbs_all_cues.items():\n",
    "        \n",
    "        # Initialise vector of values\n",
    "        vt = np.empty(len(fbs))\n",
    "        vt.fill(np.nan)\n",
    "        \n",
    "        # Fill in prior\n",
    "        # If want specific prior per cue, check value of cue\n",
    "        vt[0] = v0\n",
    "        \n",
    "        # Iterate to fill in vector\n",
    "        for t in range(1,len(vt)):\n",
    "            \n",
    "            # Compute prediction error\n",
    "            pe = fbs[t-1] - vt[t-1]\n",
    "            \n",
    "            # Compute new vt and fill in \n",
    "            vt[t] = vt[t-1] + alpha * pe\n",
    "        \n",
    "        vt_all_cues[cue] = vt\n",
    "    \n",
    "    return vt_all_cues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d69aff24-9804-482e-b448-8be86984c6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_softmax(vt_all_cues, param_values, param_names):\n",
    "    \n",
    "    # Free parameters\n",
    "    beta = param_values[param_names.index('beta')]\n",
    "    \n",
    "    # Initialise empty dicitonnary\n",
    "    p_hit_all_cues = dict.fromkeys(vt_all_cues.keys())\n",
    "    \n",
    "    # Iterate over cues\n",
    "    for cue, vt in vt_all_cues.items():\n",
    "        \n",
    "        x = beta*vt\n",
    "        \n",
    "        try:\n",
    "            p_hit =  np.exp(x)/(np.exp(x)+1)\n",
    "        except RuntimeWarning:\n",
    "            # to avoid overflow errors\n",
    "            expon_bound = 700\n",
    "            p_hit = [1 if el>expon_bound else (np.exp(el)/(np.exp(el)+1)) for el in x]\n",
    "            \n",
    "        p_hit_all_cues[cue] = p_hit\n",
    "    \n",
    "    return p_hit_all_cues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bf8a6d8e-892e-4e39-8d4b-23ab909cd758",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    \n",
    "    def __init__(self, value_fct, dec_fct, param_names):\n",
    "        self.value_fct = value_fct\n",
    "        self.dec_fct = dec_fct\n",
    "        self.param_names = param_names\n",
    "        self.param_values = []\n",
    "        self.values = []\n",
    "        self.p_hit = []\n",
    "        self.nLLs = []\n",
    "        self.total_nLL = []\n",
    "        self.fbs_all_cues = []\n",
    "        self.isHit_all_cues = []\n",
    "    \n",
    "    def set_param_values(self, param_values):\n",
    "        self.param_values = param_values\n",
    "            \n",
    "    def set_data(self, fbs_all_cues, isHit_all_cues):\n",
    "        self.fbs_all_cues = fbs_all_cues\n",
    "        self.isHit_all_cues = isHit_all_cues\n",
    "            \n",
    "    def compute_ll_per_cue(self, p_hit_all_cues, isHit_all_cues):\n",
    "        \n",
    "        # Initialise empty dicitonnary\n",
    "        nLLs_all_cues = dict.fromkeys(p_hit_all_cues.keys())\n",
    "        total_nLL_all_cues = dict.fromkeys(p_hit_all_cues.keys())\n",
    "        \n",
    "        # Iterate over cues\n",
    "        for cue, p_hit in p_hit_all_cues.items():\n",
    "            isHit = isHit_all_cues[cue]\n",
    "            # compute likelihoods of choices\n",
    "            ll_choice = []\n",
    "            almost_zero = np.finfo(float).tiny\n",
    "            for ind, hit in enumerate(isHit):\n",
    "                if hit==1:\n",
    "                    p_ =  p_hit[ind]\n",
    "                else:\n",
    "                    p_ =  1-p_hit[ind]\n",
    "                    \n",
    "                ll_choice.append(almost_zero if p_<almost_zero else p_)\n",
    "                             \n",
    "            nLLs = -np.log(ll_choice)\n",
    "            nLLs_all_cues[cue] = nLLs\n",
    "            total_nLL_all_cues[cue] = sum(nLLs)\n",
    "            \n",
    "        return total_nLL_all_cues, nLLs_all_cues\n",
    "    \n",
    "    def compute_nLL(self, param_values):\n",
    "        \n",
    "        fbs_all_cues = self.fbs_all_cues\n",
    "        isHit_all_cues = self.isHit_all_cues\n",
    "        \n",
    "        # set parameter values\n",
    "        self.set_param_values(param_values)\n",
    "\n",
    "        # compute expected values\n",
    "        vt_all_cues = self.value_fct(fbs_all_cues, self.param_values, self.param_names)\n",
    "        \n",
    "        # compute hit probability\n",
    "        p_hit_all_cues  = self.dec_fct(vt_all_cues, self.param_values, self.param_names)\n",
    "        \n",
    "        # compute nLL per cue\n",
    "        total_nLL_all_cues, nLLs_all_cues = self.compute_ll_per_cue(p_hit_all_cues, isHit_all_cues)\n",
    "\n",
    "        # compute total neg LL (sum over cues, i.e. multiply likelihoods)\n",
    "        nLL = sum(total_nLL_all_cues.values())\n",
    "        \n",
    "        # Set values\n",
    "        self.v = vt_all_cues\n",
    "        self.p_hit = p_hit_all_cues\n",
    "        self.nLLs = nLLs_all_cues\n",
    "        self.total_nLL = total_nLL_all_cues\n",
    "        \n",
    "        return nLL\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac16b839-1c4f-43a6-ab92-139f14deba19",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Create a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e700c41f-2a09-4379-b48a-38017efae65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new Model object\n",
    "mod1 = Model(value_fct = rescorla_wagner, \n",
    "             dec_fct = my_softmax, \n",
    "             param_names = ['v0', 'alpha', 'beta'])\n",
    "\n",
    "# Input data to model\n",
    "mod1.set_data(fbs_all_cues, isHit_all_cues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "62d10ad7-3e42-47bd-b2de-aee10c37b64e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58.812518653565505\n"
     ]
    }
   ],
   "source": [
    "# Parameter values\n",
    "param_values = [0.5, 0.2, 1]\n",
    "\n",
    "# Compute nLL of model given param values\n",
    "nLL = mod1.compute_nLL(param_values)\n",
    "\n",
    "print(nLL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f2b3bb4c-27da-4cba-88c0-8fea6fe14655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free parameters\n",
    "alpha_values = np.linspace(0,1,20)\n",
    "v0_values = np.linspace(-5,5,20)\n",
    "beta_values = np.linspace(0,2,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ff9b6f07-f873-4eef-b442-9179fd3bccac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting...\n",
      "0\n",
      "10\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "# initialise matrix of nlls (+ alphas and v0 for plotting)\n",
    "mat_nLL = np.full([len(alpha_values), len(v0_values), len(beta_values)], np.nan)\n",
    "mat_alpha = np.full([len(alpha_values), len(v0_values), len(beta_values)], np.nan)\n",
    "mat_v0 = np.full([len(alpha_values), len(v0_values), len(beta_values)], np.nan)\n",
    "mat_beta = np.full([len(alpha_values), len(v0_values), len(beta_values)], np.nan)\n",
    "\n",
    "# Compute nLL for different alphas and nLLs\n",
    "print('starting...')\n",
    "for i_alpha, alpha in enumerate(alpha_values):\n",
    "    if i_alpha%10==0:\n",
    "        print(i_alpha)\n",
    "    for i_v0, v0 in enumerate(v0_values):\n",
    "        for i_beta, beta in enumerate(beta_values):\n",
    "            mat_nLL[i_alpha][i_v0][i_beta] = mod1.compute_nLL([v0, alpha, beta])        \n",
    "            mat_alpha[i_alpha][i_v0][i_beta] = alpha\n",
    "            mat_v0[i_alpha][i_v0][i_beta] = v0\n",
    "            mat_beta[i_alpha][i_v0][i_beta] = beta\n",
    "print('DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6cee6b3e-5614-44ee-bbe2-e0a935d6d34c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best v0 is = 0.7894736842105257\n",
      "Best alpha is = 0.05263157894736842\n",
      "Best beta is = 1.6842105263157894\n",
      "Min nLL is = 50.457355216794426\n"
     ]
    }
   ],
   "source": [
    "# Extract best parameter\n",
    "nLL_min = np.amin(mat_nLL)\n",
    "ind_min = np.where(mat_nLL == nLL_min)\n",
    "best_alpha = mat_alpha[ind_min]\n",
    "best_v0 = mat_v0[ind_min]\n",
    "best_beta = mat_beta[ind_min]\n",
    "\n",
    "print('Best v0 is = ' + str(best_v0[0]) + \n",
    "      '\\nBest alpha is = ' + str(best_alpha[0]) + \n",
    "      '\\nBest beta is = ' + str(best_beta[0]) + \n",
    "      '\\nMin nLL is = ' + str(nLL_min))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0220b1ca-f2cc-4d62-baac-306dd44a7305",
   "metadata": {},
   "source": [
    "# Minimise nLL with optimisation methods (sklearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c96a5e-b5c5-4b0b-9c90-38c64f085c71",
   "metadata": {},
   "source": [
    "## Initial guess bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "33068d48-1205-474e-aeed-ab0a5b2bfa31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ['v0', 'alpha', 'beta']\n",
    "# define range for input\n",
    "param_lower_bound = [-5, 0, 0]\n",
    "param_upper_bound = [ 5, 1, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c160a8e-022c-4f6c-9aa1-ae7f8d252cf7",
   "metadata": {},
   "source": [
    "## Nelder-mead optimisation (direct search method, no gradient computation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "053cc4c7-4aae-4eb8-a1a7-353fda86c58c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mat_min_nLL=[]\n",
    "mat_best_params=[]\n",
    "\n",
    "for i in range(0,5):\n",
    "\n",
    "    # define the starting point as a random sample from the domain\n",
    "    initial_guess = np.array(param_lower_bound) + np.random.rand(len(param_lower_bound)) * (np.array(param_upper_bound) - np.array(param_lower_bound))\n",
    "\n",
    "    # find the min likelihood\n",
    "    result = minimize(mod1.compute_nLL, initial_guess, method='nelder-mead',\n",
    "                   options={'xatol': 1e-8, 'disp': False})\n",
    "\n",
    "    # store min_nLL and parameters\n",
    "    mat_min_nLL.append(result.fun)\n",
    "    mat_best_params.append(result.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8d3c9d6b-0e96-403a-b529-f116cd5c9194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.41154191045795\n",
      "['v0', 'alpha', 'beta']\n",
      "[0.62629941 0.04190244 1.98528227]\n"
     ]
    }
   ],
   "source": [
    "ind = np.argmin(mat_min_nLL)\n",
    "print(mat_min_nLL[ind])\n",
    "print(mod1.param_names)\n",
    "print(mat_best_params[ind])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc179cc-0559-440d-b2f0-23e041eae2d6",
   "metadata": {},
   "source": [
    "## Powell optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6409e7da-a385-492a-822a-0a9388b2f8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_min_nLL=[]\n",
    "mat_best_params=[]\n",
    "\n",
    "for i in range(0,5):\n",
    "    \n",
    "    # define the starting point as a random sample from the domain\n",
    "    initial_guess = np.array(param_lower_bound) + np.random.rand(len(param_lower_bound)) * (np.array(param_upper_bound) - np.array(param_lower_bound))\n",
    "    \n",
    "    # find the min likelihood\n",
    "    result = minimize(mod1.compute_nLL, initial_guess, method='Powell',\n",
    "                   options={'xtol': 1e-8, 'disp': False})\n",
    "\n",
    "    # store min_nLL and parameters\n",
    "    mat_min_nLL.append(result.fun)\n",
    "    mat_best_params.append(result.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ea38bee8-5a76-4021-b353-7e2773786519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.41158908605015\n",
      "['v0', 'alpha', 'beta']\n",
      "[0.62657408 0.04202394 1.98124008]\n"
     ]
    }
   ],
   "source": [
    "ind = np.argmin(mat_min_nLL)\n",
    "print(mat_min_nLL[ind])\n",
    "print(mod1.param_names)\n",
    "print(mat_best_params[ind])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337d1123-5c62-44a4-b6b1-10db5670ef9c",
   "metadata": {},
   "source": [
    "## CG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "55a652be-1ad1-417c-859c-48a011669aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_min_nLL=[]\n",
    "mat_best_params=[]\n",
    "\n",
    "for i in range(0,5):\n",
    "    \n",
    "    # define the starting point as a random sample from the domain\n",
    "    initial_guess = np.array(param_lower_bound) + np.random.rand(len(param_lower_bound)) * (np.array(param_upper_bound) - np.array(param_lower_bound))\n",
    "    \n",
    "    # find the min likelihood\n",
    "    result = minimize(mod1.compute_nLL, initial_guess, method='CG',\n",
    "                   options={'gtol': 1e-8, 'disp': False})\n",
    "    \n",
    "    # store min_nLL and parameters\n",
    "    mat_min_nLL.append(result.fun)\n",
    "    mat_best_params.append(result.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "58128089-c160-43ba-a4d9-b08656ad2277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.411541910882946\n",
      "['v0', 'alpha', 'beta']\n",
      "[0.62631803 0.04190346 1.98524181]\n"
     ]
    }
   ],
   "source": [
    "ind = np.argmin(mat_min_nLL)\n",
    "print(mat_min_nLL[ind])\n",
    "print(mod1.param_names)\n",
    "print(mat_best_params[ind])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14186364-362d-4fef-b2cf-84f1443ffcbd",
   "metadata": {},
   "source": [
    "## BFGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "8fb55877-5694-4237-9ddc-c916f111373c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_min_nLL=[]\n",
    "mat_best_params=[]\n",
    "\n",
    "for i in range(0,5):\n",
    "    \n",
    "    # define the starting point as a random sample from the domain\n",
    "    initial_guess = np.array(param_lower_bound) + np.random.rand(len(param_lower_bound)) * (np.array(param_upper_bound) - np.array(param_lower_bound))\n",
    "    \n",
    "    # find the min likelihood\n",
    "    result = minimize(mod1.compute_nLL, initial_guess, method='BFGS',\n",
    "                   options={'gtol': 1e-8, 'disp': False})\n",
    "    \n",
    "    # store min_nLL and parameters\n",
    "    mat_min_nLL.append(result.fun)\n",
    "    mat_best_params.append(result.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "ad6eb0a0-de56-4739-b523-7da6c1841857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.41154191046198\n",
      "['v0', 'alpha', 'beta']\n",
      "[0.62629763 0.04190234 1.98528589]\n"
     ]
    }
   ],
   "source": [
    "ind = np.argmin(mat_min_nLL)\n",
    "print(mat_min_nLL[ind])\n",
    "print(mod1.param_names)\n",
    "print(mat_best_params[ind])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dde6757-2169-4c9f-b2d5-d521dc54ee75",
   "metadata": {},
   "source": [
    "# Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "6d450218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# different lerning rate pour pnish cue et reward cue\n",
    "\n",
    "# ensuite faire pour chaque participant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8195244b-7d45-4d16-9ef0-8c8ee3056347",
   "metadata": {},
   "source": [
    "# Fit mod1 for each participant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "503779d8-b238-4a83-af74-ff9a53c761cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ID = '007'\n",
    "\n",
    "# Get data\n",
    "user_folder = 'data/user_' + ID + '/'\n",
    "df2_cf = pd.read_pickle(user_folder + 'df2_cf.pkl')\n",
    "\n",
    "# Exctract hits and fbs per cue\n",
    "isHit_all_cues, fbs_all_cues = extract_hits_fbs(df2_cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f96f576-9593-43be-8250-c1323f4e1861",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
